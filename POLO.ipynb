{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(1,)\n",
      "[1.]\n",
      "[-1.]\n",
      "Box(2,)\n",
      "[0.6  0.07]\n",
      "[-1.2  -0.07]\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(env.action_space.high)\n",
    "print(env.action_space.low)\n",
    "print(env.observation_space)\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57964144  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = env.env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.49342415,  0.01596824]), -0.1, False, {})\n",
      "(array([-0.47618191,  0.01724224]), -0.1, False, {})\n",
      "(array([-0.4577941 ,  0.01838781]), -0.1, False, {})\n",
      "(array([-0.43839663,  0.01939747]), -0.1, False, {})\n",
      "(array([-0.41813124,  0.02026539]), -0.1, False, {})\n",
      "(array([-0.39714372,  0.02098752]), -0.1, False, {})\n",
      "(array([-0.37558202,  0.02156169]), -0.1, False, {})\n",
      "(array([-0.35359433,  0.02198769]), -0.1, False, {})\n",
      "(array([-0.33132712,  0.02226722]), -0.1, False, {})\n",
      "(array([-0.30892329,  0.02240383]), -0.1, False, {})\n",
      "(array([-0.28652051,  0.02240278]), -0.1, False, {})\n",
      "(array([-0.26424966,  0.02227085]), -0.1, False, {})\n",
      "(array([-0.24223354,  0.02201613]), -0.1, False, {})\n",
      "(array([-0.22058584,  0.0216477 ]), -0.1, False, {})\n",
      "(array([-0.19941042,  0.02117542]), -0.1, False, {})\n",
      "(array([-0.17880084,  0.02060958]), -0.1, False, {})\n",
      "(array([-0.15884014,  0.0199607 ]), -0.1, False, {})\n",
      "(array([-0.13960092,  0.01923921]), -0.1, False, {})\n",
      "(array([-0.12114565,  0.01845527]), -0.1, False, {})\n",
      "(array([-0.10352709,  0.01761857]), -0.1, False, {})\n",
      "(array([-0.08678891,  0.01673818]), -0.1, False, {})\n",
      "(array([-0.07096647,  0.01582244]), -0.1, False, {})\n",
      "(array([-0.05608759,  0.01487888]), -0.1, False, {})\n",
      "(array([-0.0421734 ,  0.01391419]), -0.1, False, {})\n",
      "(array([-0.02923922,  0.01293417]), -0.1, False, {})\n",
      "(array([-0.01729544,  0.01194378]), -0.1, False, {})\n",
      "(array([-0.00634829,  0.01094715]), -0.1, False, {})\n",
      "(array([0.00359931, 0.0099476 ]), -0.1, False, {})\n",
      "(array([0.01254706, 0.00894775]), -0.1, False, {})\n",
      "(array([0.02049658, 0.00794952]), -0.1, False, {})\n",
      "(array([0.02745082, 0.00695424]), -0.1, False, {})\n",
      "(array([0.03341354, 0.00596272]), -0.1, False, {})\n",
      "(array([0.03838881, 0.00497527]), -0.1, False, {})\n",
      "(array([0.04238063, 0.00399183]), -0.1, False, {})\n",
      "(array([0.04539264, 0.00301201]), -0.1, False, {})\n",
      "(array([0.04742779, 0.00203515]), -0.1, False, {})\n",
      "(array([0.0484882 , 0.00106041]), -0.1, False, {})\n",
      "(array([4.85750214e-02, 8.68171128e-05]), -0.1, False, {})\n",
      "(array([ 0.04768834, -0.00088669]), -0.1, False, {})\n",
      "(array([ 0.04582719, -0.00186114]), -0.1, False, {})\n",
      "(array([ 0.04298964, -0.00283755]), -0.1, False, {})\n",
      "(array([ 0.03917284, -0.00381679]), -0.1, False, {})\n",
      "(array([ 0.0343733 , -0.00479955]), -0.1, False, {})\n",
      "(array([ 0.02858703, -0.00578627]), -0.1, False, {})\n",
      "(array([ 0.02180995, -0.00677708]), -0.1, False, {})\n",
      "(array([ 0.01403822, -0.00777173]), -0.1, False, {})\n",
      "(array([ 0.0052687 , -0.00876951]), -0.1, False, {})\n",
      "(array([-0.0045005, -0.0097692]), -0.1, False, {})\n",
      "(array([-0.01526948, -0.01076897]), -0.1, False, {})\n",
      "(array([-0.02703583, -0.01176635]), -0.1, False, {})\n",
      "(array([-0.03979396, -0.01275813]), -0.1, False, {})\n",
      "(array([-0.0535343 , -0.01374034]), -0.1, False, {})\n",
      "(array([-0.06824247, -0.01470817]), -0.1, False, {})\n",
      "(array([-0.08389843, -0.01565596]), -0.1, False, {})\n",
      "(array([-0.10047561, -0.01657719]), -0.1, False, {})\n",
      "(array([-0.11794008, -0.01746447]), -0.1, False, {})\n",
      "(array([-0.1362497 , -0.01830961]), -0.1, False, {})\n",
      "(array([-0.15535335, -0.01910366]), -0.1, False, {})\n",
      "(array([-0.17519038, -0.01983702]), -0.1, False, {})\n",
      "(array([-0.19568999, -0.02049962]), -0.1, False, {})\n",
      "(array([-0.21677103, -0.02108103]), -0.1, False, {})\n",
      "(array([-0.2383418 , -0.02157077]), -0.1, False, {})\n",
      "(array([-0.26030026, -0.02195846]), -0.1, False, {})\n",
      "(array([-0.28253442, -0.02223416]), -0.1, False, {})\n",
      "(array([-0.30492304, -0.02238862]), -0.1, False, {})\n",
      "(array([-0.32733659, -0.02241355]), -0.1, False, {})\n",
      "(array([-0.34963852, -0.02230193]), -0.1, False, {})\n",
      "(array([-0.37168673, -0.02204821]), -0.1, False, {})\n",
      "(array([-0.39333524, -0.02164852]), -0.1, False, {})\n",
      "(array([-0.41443606, -0.02110082]), -0.1, False, {})\n",
      "(array([-0.43484104, -0.02040498]), -0.1, False, {})\n",
      "(array([-0.45440387, -0.01956283]), -0.1, False, {})\n",
      "(array([-0.47298194, -0.01857807]), -0.1, False, {})\n",
      "(array([-0.49043817, -0.01745624]), -0.1, False, {})\n",
      "(array([-0.5066427 , -0.01620453]), -0.1, False, {})\n",
      "(array([-0.52147435, -0.01483165]), -0.1, False, {})\n",
      "(array([-0.53482193, -0.01334758]), -0.1, False, {})\n",
      "(array([-0.54658535, -0.01176342]), -0.1, False, {})\n",
      "(array([-0.55667651, -0.01009116]), -0.1, False, {})\n",
      "(array([-0.56502   , -0.00834348]), -0.1, False, {})\n",
      "(array([-0.57155362, -0.00653362]), -0.1, False, {})\n",
      "(array([-0.57622882, -0.0046752 ]), -0.1, False, {})\n",
      "(array([-0.57901094, -0.00278211]), -0.1, False, {})\n",
      "(array([-0.57987937, -0.00086843]), -0.1, False, {})\n",
      "(array([-0.5788277 ,  0.00105167]), -0.1, False, {})\n",
      "(array([-0.57586371,  0.00296399]), -0.1, False, {})\n",
      "(array([-0.57100934,  0.00485437]), -0.1, False, {})\n",
      "(array([-0.56430058,  0.00670876]), -0.1, False, {})\n",
      "(array([-0.55578732,  0.00851326]), -0.1, False, {})\n",
      "(array([-0.54553302,  0.0102543 ]), -0.1, False, {})\n",
      "(array([-0.53361433,  0.01191869]), -0.1, False, {})\n",
      "(array([-0.52012054,  0.01349379]), -0.1, False, {})\n",
      "(array([-0.50515283,  0.01496771]), -0.1, False, {})\n",
      "(array([-0.48882339,  0.01632943]), -0.1, False, {})\n",
      "(array([-0.4712543 ,  0.01756909]), -0.1, False, {})\n",
      "(array([-0.45257618,  0.01867812]), -0.1, False, {})\n",
      "(array([-0.43292671,  0.01964947]), -0.1, False, {})\n",
      "(array([-0.41244893,  0.02047779]), -0.1, False, {})\n",
      "(array([-0.3912894 ,  0.02115952]), -0.1, False, {})\n",
      "(array([-0.36959634,  0.02169306]), -0.1, False, {})\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    state = env.step([1])\n",
    "    print(state)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.state = init\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55226439  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    env.step([1])\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden, output_dim):\n",
    "        super(ValueNet, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ValueNet(3, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueNet(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=16, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([16, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())\n",
    "# print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3720], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"Pendulum-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.shape[0])\n",
    "print(env.action_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYER = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HIDDEN_LAYER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-a216c7cafcf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValueNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_LAYER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'HIDDEN_LAYER' is not defined"
     ]
    }
   ],
   "source": [
    "net = ValueNet(env.observation_space.shape[0], HIDDEN_LAYER, env.action_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueNet(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=16, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = torch.tensor([[1.0,3.0,4.0],[2.0,3.0,4.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = torch.randn(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8643,  1.0641,  2.4163]])\n"
     ]
    }
   ],
   "source": [
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 3., 4.],\n",
      "        [2., 3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1146],\n",
      "        [0.1201]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1.0], [2.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueNet(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=16, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100\t0\ttensor([[-100.]])\n",
      "-100\t1\ttensor([[-100.]])\n",
      "-100\t2\ttensor([[-100.]])\n",
      "-100\t3\ttensor([[-100.]])\n",
      "-100\t4\ttensor([[-100.]])\n",
      "-100\t5\ttensor([[-100.]])\n",
      "-100\t6\ttensor([[-100.]])\n",
      "-100\t7\ttensor([[-100.]])\n",
      "-100\t8\ttensor([[-100.]])\n",
      "-100\t9\ttensor([[-100.]])\n",
      "-100\t10\ttensor([[-100.]])\n",
      "-100\t11\ttensor([[-100.]])\n",
      "-100\t12\ttensor([[-100.]])\n",
      "-100\t13\ttensor([[-100.]])\n",
      "-100\t14\ttensor([[-100.]])\n",
      "-100\t15\ttensor([[-100.]])\n",
      "-100\t16\ttensor([[-100.]])\n",
      "-100\t17\ttensor([[-100.]])\n",
      "-100\t18\ttensor([[-100.]])\n",
      "-100\t19\ttensor([[-100.]])\n",
      "-100\t20\ttensor([[-100.]])\n",
      "-100\t21\ttensor([[-100.]])\n",
      "-100\t22\ttensor([[-100.]])\n",
      "-100\t23\ttensor([[-100.]])\n",
      "-100\t24\ttensor([[-100.]])\n",
      "-100\t25\ttensor([[-100.]])\n",
      "-100\t26\ttensor([[-100.]])\n",
      "-100\t27\ttensor([[-100.]])\n",
      "-100\t28\ttensor([[-100.]])\n",
      "-100\t29\ttensor([[-100.]])\n",
      "-100\t30\ttensor([[-100.]])\n",
      "-100\t31\ttensor([[-100.]])\n",
      "-100\t32\ttensor([[-100.]])\n",
      "-100\t33\ttensor([[-100.]])\n",
      "-100\t34\ttensor([[-100.]])\n",
      "-100\t35\ttensor([[-100.]])\n",
      "-100\t36\ttensor([[-100.]])\n",
      "-100\t37\ttensor([[-100.]])\n",
      "-100\t38\ttensor([[-100.]])\n",
      "-100\t39\ttensor([[-100.]])\n",
      "-100\t40\ttensor([[-100.]])\n",
      "-100\t41\ttensor([[-100.]])\n",
      "-100\t42\ttensor([[-100.]])\n",
      "-100\t43\ttensor([[-100.]])\n",
      "-100\t44\ttensor([[-100.]])\n",
      "-100\t45\ttensor([[-100.]])\n",
      "-100\t46\ttensor([[-100.]])\n",
      "-100\t47\ttensor([[-100.]])\n",
      "-100\t48\ttensor([[-100.]])\n",
      "-100\t49\ttensor([[-100.]])\n",
      "-100\t50\ttensor([[-100.]])\n",
      "-100\t51\ttensor([[-100.]])\n",
      "-100\t52\ttensor([[-100.]])\n",
      "-100\t53\ttensor([[-100.]])\n",
      "-100\t54\ttensor([[-100.]])\n",
      "-100\t55\ttensor([[-100.]])\n",
      "-100\t56\ttensor([[-100.]])\n",
      "-100\t57\ttensor([[-100.]])\n",
      "-100\t58\ttensor([[-100.]])\n",
      "-100\t59\ttensor([[-100.]])\n",
      "-100\t60\ttensor([[-100.]])\n",
      "-100\t61\ttensor([[-100.]])\n",
      "-100\t62\ttensor([[-100.]])\n",
      "-100\t63\ttensor([[-100.]])\n",
      "-100\t64\ttensor([[-100.]])\n",
      "-100\t65\ttensor([[-100.]])\n",
      "-100\t66\ttensor([[-100.]])\n",
      "-100\t67\ttensor([[-100.]])\n",
      "-100\t68\ttensor([[-100.]])\n",
      "-100\t69\ttensor([[-100.]])\n",
      "-100\t70\ttensor([[-100.]])\n",
      "-100\t71\ttensor([[-100.]])\n",
      "-100\t72\ttensor([[-100.]])\n",
      "-100\t73\ttensor([[-100.]])\n",
      "-100\t74\ttensor([[-100.]])\n",
      "-100\t75\ttensor([[-100.]])\n",
      "-100\t76\ttensor([[-100.]])\n",
      "-100\t77\ttensor([[-100.]])\n",
      "-100\t78\ttensor([[-100.]])\n",
      "-100\t79\ttensor([[-100.]])\n",
      "-100\t80\ttensor([[-100.]])\n",
      "-100\t81\ttensor([[-100.]])\n",
      "-100\t82\ttensor([[-100.]])\n",
      "-100\t83\ttensor([[-100.]])\n",
      "-100\t84\ttensor([[-100.]])\n",
      "-100\t85\ttensor([[-100.]])\n",
      "-100\t86\ttensor([[-100.]])\n",
      "-100\t87\ttensor([[-100.]])\n",
      "-100\t88\ttensor([[-100.]])\n",
      "-100\t89\ttensor([[-100.]])\n",
      "-100\t90\ttensor([[-100.]])\n",
      "-100\t91\ttensor([[-100.]])\n",
      "-100\t92\ttensor([[-100.]])\n",
      "-100\t93\ttensor([[-100.]])\n",
      "-100\t94\ttensor([[-100.]])\n",
      "-100\t95\ttensor([[-100.]])\n",
      "-100\t96\ttensor([[-100.]])\n",
      "-100\t97\ttensor([[-100.]])\n",
      "-100\t98\ttensor([[-100.]])\n",
      "-100\t99\ttensor([[-100.]])\n",
      "-99\t0\ttensor([[-99.]])\n",
      "-99\t1\ttensor([[-99.]])\n",
      "-99\t2\ttensor([[-99.]])\n",
      "-99\t3\ttensor([[-99.]])\n",
      "-99\t4\ttensor([[-99.]])\n",
      "-99\t5\ttensor([[-99.]])\n",
      "-99\t6\ttensor([[-99.]])\n",
      "-99\t7\ttensor([[-99.]])\n",
      "-99\t8\ttensor([[-99.]])\n",
      "-99\t9\ttensor([[-99.]])\n",
      "-99\t10\ttensor([[-99.]])\n",
      "-99\t11\ttensor([[-99.]])\n",
      "-99\t12\ttensor([[-99.]])\n",
      "-99\t13\ttensor([[-99.]])\n",
      "-99\t14\ttensor([[-99.]])\n",
      "-99\t15\ttensor([[-99.]])\n",
      "-99\t16\ttensor([[-99.]])\n",
      "-99\t17\ttensor([[-99.]])\n",
      "-99\t18\ttensor([[-99.]])\n",
      "-99\t19\ttensor([[-99.]])\n",
      "-99\t20\ttensor([[-99.]])\n",
      "-99\t21\ttensor([[-99.]])\n",
      "-99\t22\ttensor([[-99.]])\n",
      "-99\t23\ttensor([[-99.]])\n",
      "-99\t24\ttensor([[-99.]])\n",
      "-99\t25\ttensor([[-99.]])\n",
      "-99\t26\ttensor([[-99.]])\n",
      "-99\t27\ttensor([[-99.]])\n",
      "-99\t28\ttensor([[-99.]])\n",
      "-99\t29\ttensor([[-99.]])\n",
      "-99\t30\ttensor([[-99.]])\n",
      "-99\t31\ttensor([[-99.]])\n",
      "-99\t32\ttensor([[-99.]])\n",
      "-99\t33\ttensor([[-99.]])\n",
      "-99\t34\ttensor([[-99.]])\n",
      "-99\t35\ttensor([[-99.]])\n",
      "-99\t36\ttensor([[-99.]])\n",
      "-99\t37\ttensor([[-99.]])\n",
      "-99\t38\ttensor([[-99.]])\n",
      "-99\t39\ttensor([[-99.]])\n",
      "-99\t40\ttensor([[-99.]])\n",
      "-99\t41\ttensor([[-99.]])\n",
      "-99\t42\ttensor([[-99.]])\n",
      "-99\t43\ttensor([[-99.]])\n",
      "-99\t44\ttensor([[-99.]])\n",
      "-99\t45\ttensor([[-99.]])\n",
      "-99\t46\ttensor([[-99.]])\n",
      "-99\t47\ttensor([[-99.]])\n",
      "-99\t48\ttensor([[-99.]])\n",
      "-99\t49\ttensor([[-99.]])\n",
      "-99\t50\ttensor([[-99.]])\n",
      "-99\t51\ttensor([[-99.]])\n",
      "-99\t52\ttensor([[-99.]])\n",
      "-99\t53\ttensor([[-99.]])\n",
      "-99\t54\ttensor([[-99.]])\n",
      "-99\t55\ttensor([[-99.]])\n",
      "-99\t56\ttensor([[-99.]])\n",
      "-99\t57\ttensor([[-99.]])\n",
      "-99\t58\ttensor([[-99.]])\n",
      "-99\t59\ttensor([[-99.]])\n",
      "-99\t60\ttensor([[-99.]])\n",
      "-99\t61\ttensor([[-99.]])\n",
      "-99\t62\ttensor([[-99.]])\n",
      "-99\t63\ttensor([[-99.]])\n",
      "-99\t64\ttensor([[-99.]])\n",
      "-99\t65\ttensor([[-99.]])\n",
      "-99\t66\ttensor([[-99.]])\n",
      "-99\t67\ttensor([[-99.]])\n",
      "-99\t68\ttensor([[-99.]])\n",
      "-99\t69\ttensor([[-99.]])\n",
      "-99\t70\ttensor([[-99.]])\n",
      "-99\t71\ttensor([[-99.]])\n",
      "-99\t72\ttensor([[-99.]])\n",
      "-99\t73\ttensor([[-99.]])\n",
      "-99\t74\ttensor([[-99.]])\n",
      "-99\t75\ttensor([[-99.]])\n",
      "-99\t76\ttensor([[-99.]])\n",
      "-99\t77\ttensor([[-99.]])\n",
      "-99\t78\ttensor([[-99.]])\n",
      "-99\t79\ttensor([[-99.]])\n",
      "-99\t80\ttensor([[-99.]])\n",
      "-99\t81\ttensor([[-99.]])\n",
      "-99\t82\ttensor([[-99.]])\n",
      "-99\t83\ttensor([[-99.]])\n",
      "-99\t84\ttensor([[-99.]])\n",
      "-99\t85\ttensor([[-99.]])\n",
      "-99\t86\ttensor([[-99.]])\n",
      "-99\t87\ttensor([[-99.]])\n",
      "-99\t88\ttensor([[-99.]])\n",
      "-99\t89\ttensor([[-99.]])\n",
      "-99\t90\ttensor([[-99.]])\n",
      "-99\t91\ttensor([[-99.]])\n",
      "-99\t92\ttensor([[-99.]])\n",
      "-99\t93\ttensor([[-99.]])\n",
      "-99\t94\ttensor([[-99.]])\n",
      "-99\t95\ttensor([[-99.]])\n",
      "-99\t96\ttensor([[-99.]])\n",
      "-99\t97\ttensor([[-99.]])\n",
      "-99\t98\ttensor([[-99.]])\n",
      "-99\t99\ttensor([[-99.]])\n",
      "-98\t0\ttensor([[-98.]])\n",
      "-98\t1\ttensor([[-98.]])\n",
      "-98\t2\ttensor([[-98.]])\n",
      "-98\t3\ttensor([[-98.]])\n",
      "-98\t4\ttensor([[-98.]])\n",
      "-98\t5\ttensor([[-98.]])\n",
      "-98\t6\ttensor([[-98.]])\n",
      "-98\t7\ttensor([[-98.]])\n",
      "-98\t8\ttensor([[-98.]])\n",
      "-98\t9\ttensor([[-98.]])\n",
      "-98\t10\ttensor([[-98.]])\n",
      "-98\t11\ttensor([[-98.]])\n",
      "-98\t12\ttensor([[-98.]])\n",
      "-98\t13\ttensor([[-98.]])\n",
      "-98\t14\ttensor([[-98.]])\n",
      "-98\t15\ttensor([[-98.]])\n",
      "-98\t16\ttensor([[-98.]])\n",
      "-98\t17\ttensor([[-98.]])\n",
      "-98\t18\ttensor([[-98.]])\n",
      "-98\t19\ttensor([[-98.]])\n",
      "-98\t20\ttensor([[-98.]])\n",
      "-98\t21\ttensor([[-98.]])\n",
      "-98\t22\ttensor([[-98.]])\n",
      "-98\t23\ttensor([[-98.]])\n",
      "-98\t24\ttensor([[-98.]])\n",
      "-98\t25\ttensor([[-98.]])\n",
      "-98\t26\ttensor([[-98.]])\n",
      "-98\t27\ttensor([[-98.]])\n",
      "-98\t28\ttensor([[-98.]])\n",
      "-98\t29\ttensor([[-98.]])\n",
      "-98\t30\ttensor([[-98.]])\n",
      "-98\t31\ttensor([[-98.]])\n",
      "-98\t32\ttensor([[-98.]])\n",
      "-98\t33\ttensor([[-98.]])\n",
      "-98\t34\ttensor([[-98.]])\n",
      "-98\t35\ttensor([[-98.]])\n",
      "-98\t36\ttensor([[-98.]])\n",
      "-98\t37\ttensor([[-98.]])\n",
      "-98\t38\ttensor([[-98.]])\n",
      "-98\t39\ttensor([[-98.]])\n",
      "-98\t40\ttensor([[-98.]])\n",
      "-98\t41\ttensor([[-98.]])\n",
      "-98\t42\ttensor([[-98.]])\n",
      "-98\t43\ttensor([[-98.]])\n",
      "-98\t44\ttensor([[-98.]])\n",
      "-98\t45\ttensor([[-98.]])\n",
      "-98\t46\ttensor([[-98.]])\n",
      "-98\t47\ttensor([[-98.]])\n",
      "-98\t48\ttensor([[-98.]])\n",
      "-98\t49\ttensor([[-98.]])\n",
      "-98\t50\ttensor([[-98.]])\n",
      "-98\t51\ttensor([[-98.]])\n",
      "-98\t52\ttensor([[-98.]])\n",
      "-98\t53\ttensor([[-98.]])\n",
      "-98\t54\ttensor([[-98.]])\n",
      "-98\t55\ttensor([[-98.]])\n",
      "-98\t56\ttensor([[-98.]])\n",
      "-98\t57\ttensor([[-98.]])\n",
      "-98\t58\ttensor([[-98.]])\n",
      "-98\t59\ttensor([[-98.]])\n",
      "-98\t60\ttensor([[-98.]])\n",
      "-98\t61\ttensor([[-98.]])\n",
      "-98\t62\ttensor([[-98.]])\n",
      "-98\t63\ttensor([[-98.]])\n",
      "-98\t64\ttensor([[-98.]])\n",
      "-98\t65\ttensor([[-98.]])\n",
      "-98\t66\ttensor([[-98.]])\n",
      "-98\t67\ttensor([[-98.]])\n",
      "-98\t68\ttensor([[-98.]])\n",
      "-98\t69\ttensor([[-98.]])\n",
      "-98\t70\ttensor([[-98.]])\n",
      "-98\t71\ttensor([[-98.]])\n",
      "-98\t72\ttensor([[-98.]])\n",
      "-98\t73\ttensor([[-98.]])\n",
      "-98\t74\ttensor([[-98.]])\n",
      "-98\t75\ttensor([[-98.]])\n",
      "-98\t76\ttensor([[-98.]])\n",
      "-98\t77\ttensor([[-98.]])\n",
      "-98\t78\ttensor([[-98.]])\n",
      "-98\t79\ttensor([[-98.]])\n",
      "-98\t80\ttensor([[-98.]])\n",
      "-98\t81\ttensor([[-98.]])\n",
      "-98\t82\ttensor([[-98.]])\n",
      "-98\t83\ttensor([[-98.]])\n",
      "-98\t84\ttensor([[-98.]])\n",
      "-98\t85\ttensor([[-98.]])\n",
      "-98\t86\ttensor([[-98.]])\n",
      "-98\t87\ttensor([[-98.]])\n",
      "-98\t88\ttensor([[-98.]])\n",
      "-98\t89\ttensor([[-98.]])\n",
      "-98\t90\ttensor([[-98.]])\n",
      "-98\t91\ttensor([[-98.]])\n",
      "-98\t92\ttensor([[-98.]])\n",
      "-98\t93\ttensor([[-98.]])\n",
      "-98\t94\ttensor([[-98.]])\n",
      "-98\t95\ttensor([[-98.]])\n",
      "-98\t96\ttensor([[-98.]])\n",
      "-98\t97\ttensor([[-98.]])\n",
      "-98\t98\ttensor([[-98.]])\n",
      "-98\t99\ttensor([[-98.]])\n",
      "-97\t0\ttensor([[-97.]])\n",
      "-97\t1\ttensor([[-97.]])\n",
      "-97\t2\ttensor([[-97.]])\n",
      "-97\t3\ttensor([[-97.]])\n",
      "-97\t4\ttensor([[-97.]])\n",
      "-97\t5\ttensor([[-97.]])\n",
      "-97\t6\ttensor([[-97.]])\n",
      "-97\t7\ttensor([[-97.]])\n",
      "-97\t8\ttensor([[-97.]])\n",
      "-97\t9\ttensor([[-97.]])\n",
      "-97\t10\ttensor([[-97.]])\n",
      "-97\t11\ttensor([[-97.]])\n",
      "-97\t12\ttensor([[-97.]])\n",
      "-97\t13\ttensor([[-97.]])\n",
      "-97\t14\ttensor([[-97.]])\n",
      "-97\t15\ttensor([[-97.]])\n",
      "-97\t16\ttensor([[-97.]])\n",
      "-97\t17\ttensor([[-97.]])\n",
      "-97\t18\ttensor([[-97.]])\n",
      "-97\t19\ttensor([[-97.]])\n",
      "-97\t20\ttensor([[-97.]])\n",
      "-97\t21\ttensor([[-97.]])\n",
      "-97\t22\ttensor([[-97.]])\n",
      "-97\t23\ttensor([[-97.]])\n",
      "-97\t24\ttensor([[-97.]])\n",
      "-97\t25\ttensor([[-97.]])\n",
      "-97\t26\ttensor([[-97.]])\n",
      "-97\t27\ttensor([[-97.]])\n",
      "-97\t28\ttensor([[-97.]])\n",
      "-97\t29\ttensor([[-97.]])\n",
      "-97\t30\ttensor([[-97.]])\n",
      "-97\t31\ttensor([[-97.]])\n",
      "-97\t32\ttensor([[-97.]])\n",
      "-97\t33\ttensor([[-97.]])\n",
      "-97\t34\ttensor([[-97.]])\n",
      "-97\t35\ttensor([[-97.]])\n",
      "-97\t36\ttensor([[-97.]])\n",
      "-97\t37\ttensor([[-97.]])\n",
      "-97\t38\ttensor([[-97.]])\n",
      "-97\t39\ttensor([[-97.]])\n",
      "-97\t40\ttensor([[-97.]])\n",
      "-97\t41\ttensor([[-97.]])\n",
      "-97\t42\ttensor([[-97.]])\n",
      "-97\t43\ttensor([[-97.]])\n",
      "-97\t44\ttensor([[-97.]])\n",
      "-97\t45\ttensor([[-97.]])\n",
      "-97\t46\ttensor([[-97.]])\n",
      "-97\t47\ttensor([[-97.]])\n",
      "-97\t48\ttensor([[-97.]])\n",
      "-97\t49\ttensor([[-97.]])\n",
      "-97\t50\ttensor([[-97.]])\n",
      "-97\t51\ttensor([[-97.]])\n",
      "-97\t52\ttensor([[-97.]])\n",
      "-97\t53\ttensor([[-97.]])\n",
      "-97\t54\ttensor([[-97.]])\n",
      "-97\t55\ttensor([[-97.]])\n",
      "-97\t56\ttensor([[-97.]])\n",
      "-97\t57\ttensor([[-97.]])\n",
      "-97\t58\ttensor([[-97.]])\n",
      "-97\t59\ttensor([[-97.]])\n",
      "-97\t60\ttensor([[-97.]])\n",
      "-97\t61\ttensor([[-97.]])\n",
      "-97\t62\ttensor([[-97.]])\n",
      "-97\t63\ttensor([[-97.]])\n",
      "-97\t64\ttensor([[-97.]])\n",
      "-97\t65\ttensor([[-97.]])\n",
      "-97\t66\ttensor([[-97.]])\n",
      "-97\t67\ttensor([[-97.]])\n",
      "-97\t68\ttensor([[-97.]])\n",
      "-97\t69\ttensor([[-97.]])\n",
      "-97\t70\ttensor([[-97.]])\n",
      "-97\t71\ttensor([[-97.]])\n",
      "-97\t72\ttensor([[-97.]])\n",
      "-97\t73\ttensor([[-97.]])\n",
      "-97\t74\ttensor([[-97.]])\n",
      "-97\t75\ttensor([[-97.]])\n",
      "-97\t76\ttensor([[-97.]])\n",
      "-97\t77\ttensor([[-97.]])\n",
      "-97\t78\ttensor([[-97.]])\n",
      "-97\t79\ttensor([[-97.]])\n",
      "-97\t80\ttensor([[-97.]])\n",
      "-97\t81\ttensor([[-97.]])\n",
      "-97\t82\ttensor([[-97.]])\n",
      "-97\t83\ttensor([[-97.]])\n",
      "-97\t84\ttensor([[-97.]])\n",
      "-97\t85\ttensor([[-97.]])\n",
      "-97\t86\ttensor([[-97.]])\n",
      "-97\t87\ttensor([[-97.]])\n",
      "-97\t88\ttensor([[-97.]])\n",
      "-97\t89\ttensor([[-97.]])\n",
      "-97\t90\ttensor([[-97.]])\n",
      "-97\t91\ttensor([[-97.]])\n",
      "-97\t92\ttensor([[-97.]])\n",
      "-97\t93\ttensor([[-97.]])\n",
      "-97\t94\ttensor([[-97.]])\n",
      "-97\t95\ttensor([[-97.]])\n",
      "-97\t96\ttensor([[-97.]])\n",
      "-97\t97\ttensor([[-97.]])\n",
      "-97\t98\ttensor([[-97.]])\n",
      "-97\t99\ttensor([[-97.]])\n",
      "-96\t0\ttensor([[-96.]])\n",
      "-96\t1\ttensor([[-96.]])\n",
      "-96\t2\ttensor([[-96.]])\n",
      "-96\t3\ttensor([[-96.]])\n",
      "-96\t4\ttensor([[-96.]])\n",
      "-96\t5\ttensor([[-96.]])\n",
      "-96\t6\ttensor([[-96.]])\n",
      "-96\t7\ttensor([[-96.]])\n",
      "-96\t8\ttensor([[-96.]])\n",
      "-96\t9\ttensor([[-96.]])\n",
      "-96\t10\ttensor([[-96.]])\n",
      "-96\t11\ttensor([[-96.]])\n",
      "-96\t12\ttensor([[-96.]])\n",
      "-96\t13\ttensor([[-96.]])\n",
      "-96\t14\ttensor([[-96.]])\n",
      "-96\t15\ttensor([[-96.]])\n",
      "-96\t16\ttensor([[-96.]])\n",
      "-96\t17\ttensor([[-96.]])\n",
      "-96\t18\ttensor([[-96.]])\n",
      "-96\t19\ttensor([[-96.]])\n",
      "-96\t20\ttensor([[-96.]])\n",
      "-96\t21\ttensor([[-96.]])\n",
      "-96\t22\ttensor([[-96.]])\n",
      "-96\t23\ttensor([[-96.]])\n",
      "-96\t24\ttensor([[-96.]])\n",
      "-96\t25\ttensor([[-96.]])\n",
      "-96\t26\ttensor([[-96.]])\n",
      "-96\t27\ttensor([[-96.]])\n",
      "-96\t28\ttensor([[-96.]])\n",
      "-96\t29\ttensor([[-96.]])\n",
      "-96\t30\ttensor([[-96.]])\n",
      "-96\t31\ttensor([[-96.]])\n",
      "-96\t32\ttensor([[-96.]])\n",
      "-96\t33\ttensor([[-96.]])\n",
      "-96\t34\ttensor([[-96.]])\n",
      "-96\t35\ttensor([[-96.]])\n",
      "-96\t36\ttensor([[-96.]])\n",
      "-96\t37\ttensor([[-96.]])\n",
      "-96\t38\ttensor([[-96.]])\n",
      "-96\t39\ttensor([[-96.]])\n",
      "-96\t40\ttensor([[-96.]])\n",
      "-96\t41\ttensor([[-96.]])\n",
      "-96\t42\ttensor([[-96.]])\n",
      "-96\t43\ttensor([[-96.]])\n",
      "-96\t44\ttensor([[-96.]])\n",
      "-96\t45\ttensor([[-96.]])\n",
      "-96\t46\ttensor([[-96.]])\n",
      "-96\t47\ttensor([[-96.]])\n",
      "-96\t48\ttensor([[-96.]])\n",
      "-96\t49\ttensor([[-96.]])\n",
      "-96\t50\ttensor([[-96.]])\n",
      "-96\t51\ttensor([[-96.]])\n",
      "-96\t52\ttensor([[-96.]])\n",
      "-96\t53\ttensor([[-96.]])\n",
      "-96\t54\ttensor([[-96.]])\n",
      "-96\t55\ttensor([[-96.]])\n",
      "-96\t56\ttensor([[-96.]])\n",
      "-96\t57\ttensor([[-96.]])\n",
      "-96\t58\ttensor([[-96.]])\n",
      "-96\t59\ttensor([[-96.]])\n",
      "-96\t60\ttensor([[-96.]])\n",
      "-96\t61\ttensor([[-96.]])\n",
      "-96\t62\ttensor([[-96.]])\n",
      "-96\t63\ttensor([[-96.]])\n",
      "-96\t64\ttensor([[-96.]])\n",
      "-96\t65\ttensor([[-96.]])\n",
      "-96\t66\ttensor([[-96.]])\n",
      "-96\t67\ttensor([[-96.]])\n",
      "-96\t68\ttensor([[-96.]])\n",
      "-96\t69\ttensor([[-96.]])\n",
      "-96\t70\ttensor([[-96.]])\n",
      "-96\t71\ttensor([[-96.]])\n",
      "-96\t72\ttensor([[-96.]])\n",
      "-96\t73\ttensor([[-96.]])\n",
      "-96\t74\ttensor([[-96.]])\n",
      "-96\t75\ttensor([[-96.]])\n",
      "-96\t76\ttensor([[-96.]])\n",
      "-96\t77\ttensor([[-96.]])\n",
      "-96\t78\ttensor([[-96.]])\n",
      "-96\t79\ttensor([[-96.]])\n",
      "-96\t80\ttensor([[-96.]])\n",
      "-96\t81\ttensor([[-96.]])\n",
      "-96\t82\ttensor([[-96.]])\n",
      "-96\t83\ttensor([[-96.]])\n",
      "-96\t84\ttensor([[-96.]])\n",
      "-96\t85\ttensor([[-96.]])\n",
      "-96\t86\ttensor([[-96.]])\n",
      "-96\t87\ttensor([[-96.]])\n",
      "-96\t88\ttensor([[-96.]])\n",
      "-96\t89\ttensor([[-96.]])\n",
      "-96\t90\ttensor([[-96.]])\n",
      "-96\t91\ttensor([[-96.]])\n",
      "-96\t92\ttensor([[-96.]])\n",
      "-96\t93\ttensor([[-96.]])\n",
      "-96\t94\ttensor([[-96.]])\n",
      "-96\t95\ttensor([[-96.]])\n",
      "-96\t96\ttensor([[-96.]])\n",
      "-96\t97\ttensor([[-96.]])\n",
      "-96\t98\ttensor([[-96.]])\n",
      "-96\t99\ttensor([[-96.]])\n",
      "-95\t0\ttensor([[-95.]])\n",
      "-95\t1\ttensor([[-95.]])\n",
      "-95\t2\ttensor([[-95.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-95\t3\ttensor([[-95.]])\n",
      "-95\t4\ttensor([[-95.]])\n",
      "-95\t5\ttensor([[-95.]])\n",
      "-95\t6\ttensor([[-95.]])\n",
      "-95\t7\ttensor([[-95.]])\n",
      "-95\t8\ttensor([[-95.]])\n",
      "-95\t9\ttensor([[-95.]])\n",
      "-95\t10\ttensor([[-95.]])\n",
      "-95\t11\ttensor([[-95.]])\n",
      "-95\t12\ttensor([[-95.]])\n",
      "-95\t13\ttensor([[-95.]])\n",
      "-95\t14\ttensor([[-95.]])\n",
      "-95\t15\ttensor([[-95.]])\n",
      "-95\t16\ttensor([[-95.]])\n",
      "-95\t17\ttensor([[-95.]])\n",
      "-95\t18\ttensor([[-95.]])\n",
      "-95\t19\ttensor([[-95.]])\n",
      "-95\t20\ttensor([[-95.]])\n",
      "-95\t21\ttensor([[-95.]])\n",
      "-95\t22\ttensor([[-95.]])\n",
      "-95\t23\ttensor([[-95.]])\n",
      "-95\t24\ttensor([[-95.]])\n",
      "-95\t25\ttensor([[-95.]])\n",
      "-95\t26\ttensor([[-95.]])\n",
      "-95\t27\ttensor([[-95.]])\n",
      "-95\t28\ttensor([[-95.]])\n",
      "-95\t29\ttensor([[-95.]])\n",
      "-95\t30\ttensor([[-95.]])\n",
      "-95\t31\ttensor([[-95.]])\n",
      "-95\t32\ttensor([[-95.]])\n",
      "-95\t33\ttensor([[-95.]])\n",
      "-95\t34\ttensor([[-95.]])\n",
      "-95\t35\ttensor([[-95.]])\n",
      "-95\t36\ttensor([[-95.]])\n",
      "-95\t37\ttensor([[-95.]])\n",
      "-95\t38\ttensor([[-95.]])\n",
      "-95\t39\ttensor([[-95.]])\n",
      "-95\t40\ttensor([[-95.]])\n",
      "-95\t41\ttensor([[-95.]])\n",
      "-95\t42\ttensor([[-95.]])\n",
      "-95\t43\ttensor([[-95.]])\n",
      "-95\t44\ttensor([[-95.]])\n",
      "-95\t45\ttensor([[-95.]])\n",
      "-95\t46\ttensor([[-95.]])\n",
      "-95\t47\ttensor([[-95.]])\n",
      "-95\t48\ttensor([[-95.]])\n",
      "-95\t49\ttensor([[-95.]])\n",
      "-95\t50\ttensor([[-95.]])\n",
      "-95\t51\ttensor([[-95.]])\n",
      "-95\t52\ttensor([[-95.]])\n",
      "-95\t53\ttensor([[-95.]])\n",
      "-95\t54\ttensor([[-95.]])\n",
      "-95\t55\ttensor([[-95.]])\n",
      "-95\t56\ttensor([[-95.]])\n",
      "-95\t57\ttensor([[-95.]])\n",
      "-95\t58\ttensor([[-95.]])\n",
      "-95\t59\ttensor([[-95.]])\n",
      "-95\t60\ttensor([[-95.]])\n",
      "-95\t61\ttensor([[-95.]])\n",
      "-95\t62\ttensor([[-95.]])\n",
      "-95\t63\ttensor([[-95.]])\n",
      "-95\t64\ttensor([[-95.]])\n",
      "-95\t65\ttensor([[-95.]])\n",
      "-95\t66\ttensor([[-95.]])\n",
      "-95\t67\ttensor([[-95.]])\n",
      "-95\t68\ttensor([[-95.]])\n",
      "-95\t69\ttensor([[-95.]])\n",
      "-95\t70\ttensor([[-95.]])\n",
      "-95\t71\ttensor([[-95.]])\n",
      "-95\t72\ttensor([[-95.]])\n",
      "-95\t73\ttensor([[-95.]])\n",
      "-95\t74\ttensor([[-95.]])\n",
      "-95\t75\ttensor([[-95.]])\n",
      "-95\t76\ttensor([[-95.]])\n",
      "-95\t77\ttensor([[-95.]])\n",
      "-95\t78\ttensor([[-95.]])\n",
      "-95\t79\ttensor([[-95.]])\n",
      "-95\t80\ttensor([[-95.]])\n",
      "-95\t81\ttensor([[-95.]])\n",
      "-95\t82\ttensor([[-95.]])\n",
      "-95\t83\ttensor([[-95.]])\n",
      "-95\t84\ttensor([[-95.]])\n",
      "-95\t85\ttensor([[-95.]])\n",
      "-95\t86\ttensor([[-95.]])\n",
      "-95\t87\ttensor([[-95.]])\n",
      "-95\t88\ttensor([[-95.]])\n",
      "-95\t89\ttensor([[-95.]])\n",
      "-95\t90\ttensor([[-95.]])\n",
      "-95\t91\ttensor([[-95.]])\n",
      "-95\t92\ttensor([[-95.]])\n",
      "-95\t93\ttensor([[-95.]])\n",
      "-95\t94\ttensor([[-95.]])\n",
      "-95\t95\ttensor([[-95.]])\n",
      "-95\t96\ttensor([[-95.]])\n",
      "-95\t97\ttensor([[-95.]])\n",
      "-95\t98\ttensor([[-95.]])\n",
      "-95\t99\ttensor([[-95.]])\n",
      "-94\t0\ttensor([[-94.]])\n",
      "-94\t1\ttensor([[-94.]])\n",
      "-94\t2\ttensor([[-94.]])\n",
      "-94\t3\ttensor([[-94.]])\n",
      "-94\t4\ttensor([[-94.]])\n",
      "-94\t5\ttensor([[-94.]])\n",
      "-94\t6\ttensor([[-94.]])\n",
      "-94\t7\ttensor([[-94.]])\n",
      "-94\t8\ttensor([[-94.]])\n",
      "-94\t9\ttensor([[-94.]])\n",
      "-94\t10\ttensor([[-94.]])\n",
      "-94\t11\ttensor([[-94.]])\n",
      "-94\t12\ttensor([[-94.]])\n",
      "-94\t13\ttensor([[-94.]])\n",
      "-94\t14\ttensor([[-94.]])\n",
      "-94\t15\ttensor([[-94.]])\n",
      "-94\t16\ttensor([[-94.]])\n",
      "-94\t17\ttensor([[-94.]])\n",
      "-94\t18\ttensor([[-94.]])\n",
      "-94\t19\ttensor([[-94.]])\n",
      "-94\t20\ttensor([[-94.]])\n",
      "-94\t21\ttensor([[-94.]])\n",
      "-94\t22\ttensor([[-94.]])\n",
      "-94\t23\ttensor([[-94.]])\n",
      "-94\t24\ttensor([[-94.]])\n",
      "-94\t25\ttensor([[-94.]])\n",
      "-94\t26\ttensor([[-94.]])\n",
      "-94\t27\ttensor([[-94.]])\n",
      "-94\t28\ttensor([[-94.]])\n",
      "-94\t29\ttensor([[-94.]])\n",
      "-94\t30\ttensor([[-94.]])\n",
      "-94\t31\ttensor([[-94.]])\n",
      "-94\t32\ttensor([[-94.]])\n",
      "-94\t33\ttensor([[-94.]])\n",
      "-94\t34\ttensor([[-94.]])\n",
      "-94\t35\ttensor([[-94.]])\n",
      "-94\t36\ttensor([[-94.]])\n",
      "-94\t37\ttensor([[-94.]])\n",
      "-94\t38\ttensor([[-94.]])\n",
      "-94\t39\ttensor([[-94.]])\n",
      "-94\t40\ttensor([[-94.]])\n",
      "-94\t41\ttensor([[-94.]])\n",
      "-94\t42\ttensor([[-94.]])\n",
      "-94\t43\ttensor([[-94.]])\n",
      "-94\t44\ttensor([[-94.]])\n",
      "-94\t45\ttensor([[-94.]])\n",
      "-94\t46\ttensor([[-94.]])\n",
      "-94\t47\ttensor([[-94.]])\n",
      "-94\t48\ttensor([[-94.]])\n",
      "-94\t49\ttensor([[-94.]])\n",
      "-94\t50\ttensor([[-94.]])\n",
      "-94\t51\ttensor([[-94.]])\n",
      "-94\t52\ttensor([[-94.]])\n",
      "-94\t53\ttensor([[-94.]])\n",
      "-94\t54\ttensor([[-94.]])\n",
      "-94\t55\ttensor([[-94.]])\n",
      "-94\t56\ttensor([[-94.]])\n",
      "-94\t57\ttensor([[-94.]])\n",
      "-94\t58\ttensor([[-94.]])\n",
      "-94\t59\ttensor([[-94.]])\n",
      "-94\t60\ttensor([[-94.]])\n",
      "-94\t61\ttensor([[-94.]])\n",
      "-94\t62\ttensor([[-94.]])\n",
      "-94\t63\ttensor([[-94.]])\n",
      "-94\t64\ttensor([[-94.]])\n",
      "-94\t65\ttensor([[-94.]])\n",
      "-94\t66\ttensor([[-94.]])\n",
      "-94\t67\ttensor([[-94.]])\n",
      "-94\t68\ttensor([[-94.]])\n",
      "-94\t69\ttensor([[-94.]])\n",
      "-94\t70\ttensor([[-94.]])\n",
      "-94\t71\ttensor([[-94.]])\n",
      "-94\t72\ttensor([[-94.]])\n",
      "-94\t73\ttensor([[-94.]])\n",
      "-94\t74\ttensor([[-94.]])\n",
      "-94\t75\ttensor([[-94.]])\n",
      "-94\t76\ttensor([[-94.]])\n",
      "-94\t77\ttensor([[-94.]])\n",
      "-94\t78\ttensor([[-94.]])\n",
      "-94\t79\ttensor([[-94.]])\n",
      "-94\t80\ttensor([[-94.]])\n",
      "-94\t81\ttensor([[-94.]])\n",
      "-94\t82\ttensor([[-94.]])\n",
      "-94\t83\ttensor([[-94.]])\n",
      "-94\t84\ttensor([[-94.]])\n",
      "-94\t85\ttensor([[-94.]])\n",
      "-94\t86\ttensor([[-94.]])\n",
      "-94\t87\ttensor([[-94.]])\n",
      "-94\t88\ttensor([[-94.]])\n",
      "-94\t89\ttensor([[-94.]])\n",
      "-94\t90\ttensor([[-94.]])\n",
      "-94\t91\ttensor([[-94.]])\n",
      "-94\t92\ttensor([[-94.]])\n",
      "-94\t93\ttensor([[-94.]])\n",
      "-94\t94\ttensor([[-94.]])\n",
      "-94\t95\ttensor([[-94.]])\n",
      "-94\t96\ttensor([[-94.]])\n",
      "-94\t97\ttensor([[-94.]])\n",
      "-94\t98\ttensor([[-94.]])\n",
      "-94\t99\ttensor([[-94.]])\n",
      "-93\t0\ttensor([[-93.]])\n",
      "-93\t1\ttensor([[-93.]])\n",
      "-93\t2\ttensor([[-93.]])\n",
      "-93\t3\ttensor([[-93.]])\n",
      "-93\t4\ttensor([[-93.]])\n",
      "-93\t5\ttensor([[-93.]])\n",
      "-93\t6\ttensor([[-93.]])\n",
      "-93\t7\ttensor([[-93.]])\n",
      "-93\t8\ttensor([[-93.]])\n",
      "-93\t9\ttensor([[-93.]])\n",
      "-93\t10\ttensor([[-93.]])\n",
      "-93\t11\ttensor([[-93.]])\n",
      "-93\t12\ttensor([[-93.]])\n",
      "-93\t13\ttensor([[-93.]])\n",
      "-93\t14\ttensor([[-93.]])\n",
      "-93\t15\ttensor([[-93.]])\n",
      "-93\t16\ttensor([[-93.]])\n",
      "-93\t17\ttensor([[-93.]])\n",
      "-93\t18\ttensor([[-93.]])\n",
      "-93\t19\ttensor([[-93.]])\n",
      "-93\t20\ttensor([[-93.]])\n",
      "-93\t21\ttensor([[-93.]])\n",
      "-93\t22\ttensor([[-93.]])\n",
      "-93\t23\ttensor([[-93.]])\n",
      "-93\t24\ttensor([[-93.]])\n",
      "-93\t25\ttensor([[-93.]])\n",
      "-93\t26\ttensor([[-93.]])\n",
      "-93\t27\ttensor([[-93.]])\n",
      "-93\t28\ttensor([[-93.]])\n",
      "-93\t29\ttensor([[-93.]])\n",
      "-93\t30\ttensor([[-93.]])\n",
      "-93\t31\ttensor([[-93.]])\n",
      "-93\t32\ttensor([[-93.]])\n",
      "-93\t33\ttensor([[-93.]])\n",
      "-93\t34\ttensor([[-93.]])\n",
      "-93\t35\ttensor([[-93.]])\n",
      "-93\t36\ttensor([[-93.]])\n",
      "-93\t37\ttensor([[-93.]])\n",
      "-93\t38\ttensor([[-93.]])\n",
      "-93\t39\ttensor([[-93.]])\n",
      "-93\t40\ttensor([[-93.]])\n",
      "-93\t41\ttensor([[-93.]])\n",
      "-93\t42\ttensor([[-93.]])\n",
      "-93\t43\ttensor([[-93.]])\n",
      "-93\t44\ttensor([[-93.]])\n",
      "-93\t45\ttensor([[-93.]])\n",
      "-93\t46\ttensor([[-93.]])\n",
      "-93\t47\ttensor([[-93.]])\n",
      "-93\t48\ttensor([[-93.]])\n",
      "-93\t49\ttensor([[-93.]])\n",
      "-93\t50\ttensor([[-93.]])\n",
      "-93\t51\ttensor([[-93.]])\n",
      "-93\t52\ttensor([[-93.]])\n",
      "-93\t53\ttensor([[-93.]])\n",
      "-93\t54\ttensor([[-93.]])\n",
      "-93\t55\ttensor([[-93.]])\n",
      "-93\t56\ttensor([[-93.]])\n",
      "-93\t57\ttensor([[-93.]])\n",
      "-93\t58\ttensor([[-93.]])\n",
      "-93\t59\ttensor([[-93.]])\n",
      "-93\t60\ttensor([[-93.]])\n",
      "-93\t61\ttensor([[-93.]])\n",
      "-93\t62\ttensor([[-93.]])\n",
      "-93\t63\ttensor([[-93.]])\n",
      "-93\t64\ttensor([[-93.]])\n",
      "-93\t65\ttensor([[-93.]])\n",
      "-93\t66\ttensor([[-93.]])\n",
      "-93\t67\ttensor([[-93.]])\n",
      "-93\t68\ttensor([[-93.]])\n",
      "-93\t69\ttensor([[-93.]])\n",
      "-93\t70\ttensor([[-93.]])\n",
      "-93\t71\ttensor([[-93.]])\n",
      "-93\t72\ttensor([[-93.]])\n",
      "-93\t73\ttensor([[-93.]])\n",
      "-93\t74\ttensor([[-93.]])\n",
      "-93\t75\ttensor([[-93.]])\n",
      "-93\t76\ttensor([[-93.]])\n",
      "-93\t77\ttensor([[-93.]])\n",
      "-93\t78\ttensor([[-93.]])\n",
      "-93\t79\ttensor([[-93.]])\n",
      "-93\t80\ttensor([[-93.]])\n",
      "-93\t81\ttensor([[-93.]])\n",
      "-93\t82\ttensor([[-93.]])\n",
      "-93\t83\ttensor([[-93.]])\n",
      "-93\t84\ttensor([[-93.]])\n",
      "-93\t85\ttensor([[-93.]])\n",
      "-93\t86\ttensor([[-93.]])\n",
      "-93\t87\ttensor([[-93.]])\n",
      "-93\t88\ttensor([[-93.]])\n",
      "-93\t89\ttensor([[-93.]])\n",
      "-93\t90\ttensor([[-93.]])\n",
      "-93\t91\ttensor([[-93.]])\n",
      "-93\t92\ttensor([[-93.]])\n",
      "-93\t93\ttensor([[-93.]])\n",
      "-93\t94\ttensor([[-93.]])\n",
      "-93\t95\ttensor([[-93.]])\n",
      "-93\t96\ttensor([[-93.]])\n",
      "-93\t97\ttensor([[-93.]])\n",
      "-93\t98\ttensor([[-93.]])\n",
      "-93\t99\ttensor([[-93.]])\n",
      "-92\t0\ttensor([[-92.]])\n",
      "-92\t1\ttensor([[-92.]])\n",
      "-92\t2\ttensor([[-92.]])\n",
      "-92\t3\ttensor([[-92.]])\n",
      "-92\t4\ttensor([[-92.]])\n",
      "-92\t5\ttensor([[-92.]])\n",
      "-92\t6\ttensor([[-92.]])\n",
      "-92\t7\ttensor([[-92.]])\n",
      "-92\t8\ttensor([[-92.]])\n",
      "-92\t9\ttensor([[-92.]])\n",
      "-92\t10\ttensor([[-92.]])\n",
      "-92\t11\ttensor([[-92.]])\n",
      "-92\t12\ttensor([[-92.]])\n",
      "-92\t13\ttensor([[-92.]])\n",
      "-92\t14\ttensor([[-92.]])\n",
      "-92\t15\ttensor([[-92.]])\n",
      "-92\t16\ttensor([[-92.]])\n",
      "-92\t17\ttensor([[-92.]])\n",
      "-92\t18\ttensor([[-92.]])\n",
      "-92\t19\ttensor([[-92.]])\n",
      "-92\t20\ttensor([[-92.]])\n",
      "-92\t21\ttensor([[-92.]])\n",
      "-92\t22\ttensor([[-92.]])\n",
      "-92\t23\ttensor([[-92.]])\n",
      "-92\t24\ttensor([[-92.]])\n",
      "-92\t25\ttensor([[-92.]])\n",
      "-92\t26\ttensor([[-92.]])\n",
      "-92\t27\ttensor([[-92.]])\n",
      "-92\t28\ttensor([[-92.]])\n",
      "-92\t29\ttensor([[-92.]])\n",
      "-92\t30\ttensor([[-92.]])\n",
      "-92\t31\ttensor([[-92.]])\n",
      "-92\t32\ttensor([[-92.]])\n",
      "-92\t33\ttensor([[-92.]])\n",
      "-92\t34\ttensor([[-92.]])\n",
      "-92\t35\ttensor([[-92.]])\n",
      "-92\t36\ttensor([[-92.]])\n",
      "-92\t37\ttensor([[-92.]])\n",
      "-92\t38\ttensor([[-92.]])\n",
      "-92\t39\ttensor([[-92.]])\n",
      "-92\t40\ttensor([[-92.]])\n",
      "-92\t41\ttensor([[-92.]])\n",
      "-92\t42\ttensor([[-92.]])\n",
      "-92\t43\ttensor([[-92.]])\n",
      "-92\t44\ttensor([[-92.]])\n",
      "-92\t45\ttensor([[-92.]])\n",
      "-92\t46\ttensor([[-92.]])\n",
      "-92\t47\ttensor([[-92.]])\n",
      "-92\t48\ttensor([[-92.]])\n",
      "-92\t49\ttensor([[-92.]])\n",
      "-92\t50\ttensor([[-92.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-92\t51\ttensor([[-92.]])\n",
      "-92\t52\ttensor([[-92.]])\n",
      "-92\t53\ttensor([[-92.]])\n",
      "-92\t54\ttensor([[-92.]])\n",
      "-92\t55\ttensor([[-92.]])\n",
      "-92\t56\ttensor([[-92.]])\n",
      "-92\t57\ttensor([[-92.]])\n",
      "-92\t58\ttensor([[-92.]])\n",
      "-92\t59\ttensor([[-92.]])\n",
      "-92\t60\ttensor([[-92.]])\n",
      "-92\t61\ttensor([[-92.]])\n",
      "-92\t62\ttensor([[-92.]])\n",
      "-92\t63\ttensor([[-92.]])\n",
      "-92\t64\ttensor([[-92.]])\n",
      "-92\t65\ttensor([[-92.]])\n",
      "-92\t66\ttensor([[-92.]])\n",
      "-92\t67\ttensor([[-92.]])\n",
      "-92\t68\ttensor([[-92.]])\n",
      "-92\t69\ttensor([[-92.]])\n",
      "-92\t70\ttensor([[-92.]])\n",
      "-92\t71\ttensor([[-92.]])\n",
      "-92\t72\ttensor([[-92.]])\n",
      "-92\t73\ttensor([[-92.]])\n",
      "-92\t74\ttensor([[-92.]])\n",
      "-92\t75\ttensor([[-92.]])\n",
      "-92\t76\ttensor([[-92.]])\n",
      "-92\t77\ttensor([[-92.]])\n",
      "-92\t78\ttensor([[-92.]])\n",
      "-92\t79\ttensor([[-92.]])\n",
      "-92\t80\ttensor([[-92.]])\n",
      "-92\t81\ttensor([[-92.]])\n",
      "-92\t82\ttensor([[-92.]])\n",
      "-92\t83\ttensor([[-92.]])\n",
      "-92\t84\ttensor([[-92.]])\n",
      "-92\t85\ttensor([[-92.]])\n",
      "-92\t86\ttensor([[-92.]])\n",
      "-92\t87\ttensor([[-92.]])\n",
      "-92\t88\ttensor([[-92.]])\n",
      "-92\t89\ttensor([[-92.]])\n",
      "-92\t90\ttensor([[-92.]])\n",
      "-92\t91\ttensor([[-92.]])\n",
      "-92\t92\ttensor([[-92.]])\n",
      "-92\t93\ttensor([[-92.]])\n",
      "-92\t94\ttensor([[-92.]])\n",
      "-92\t95\ttensor([[-92.]])\n",
      "-92\t96\ttensor([[-92.]])\n",
      "-92\t97\ttensor([[-92.]])\n",
      "-92\t98\ttensor([[-92.]])\n",
      "-92\t99\ttensor([[-92.]])\n",
      "-91\t0\ttensor([[-91.]])\n",
      "-91\t1\ttensor([[-91.]])\n",
      "-91\t2\ttensor([[-91.]])\n",
      "-91\t3\ttensor([[-91.]])\n",
      "-91\t4\ttensor([[-91.]])\n",
      "-91\t5\ttensor([[-91.]])\n",
      "-91\t6\ttensor([[-91.]])\n",
      "-91\t7\ttensor([[-91.]])\n",
      "-91\t8\ttensor([[-91.]])\n",
      "-91\t9\ttensor([[-91.]])\n",
      "-91\t10\ttensor([[-91.]])\n",
      "-91\t11\ttensor([[-91.]])\n",
      "-91\t12\ttensor([[-91.]])\n",
      "-91\t13\ttensor([[-91.]])\n",
      "-91\t14\ttensor([[-91.]])\n",
      "-91\t15\ttensor([[-91.]])\n",
      "-91\t16\ttensor([[-91.]])\n",
      "-91\t17\ttensor([[-91.]])\n",
      "-91\t18\ttensor([[-91.]])\n",
      "-91\t19\ttensor([[-91.]])\n",
      "-91\t20\ttensor([[-91.]])\n",
      "-91\t21\ttensor([[-91.]])\n",
      "-91\t22\ttensor([[-91.]])\n",
      "-91\t23\ttensor([[-91.]])\n",
      "-91\t24\ttensor([[-91.]])\n",
      "-91\t25\ttensor([[-91.]])\n",
      "-91\t26\ttensor([[-91.]])\n",
      "-91\t27\ttensor([[-91.]])\n",
      "-91\t28\ttensor([[-91.]])\n",
      "-91\t29\ttensor([[-91.]])\n",
      "-91\t30\ttensor([[-91.]])\n",
      "-91\t31\ttensor([[-91.]])\n",
      "-91\t32\ttensor([[-91.]])\n",
      "-91\t33\ttensor([[-91.]])\n",
      "-91\t34\ttensor([[-91.]])\n",
      "-91\t35\ttensor([[-91.]])\n",
      "-91\t36\ttensor([[-91.]])\n",
      "-91\t37\ttensor([[-91.]])\n",
      "-91\t38\ttensor([[-91.]])\n",
      "-91\t39\ttensor([[-91.]])\n",
      "-91\t40\ttensor([[-91.]])\n",
      "-91\t41\ttensor([[-91.]])\n",
      "-91\t42\ttensor([[-91.]])\n",
      "-91\t43\ttensor([[-91.]])\n",
      "-91\t44\ttensor([[-91.]])\n",
      "-91\t45\ttensor([[-91.]])\n",
      "-91\t46\ttensor([[-91.]])\n",
      "-91\t47\ttensor([[-91.]])\n",
      "-91\t48\ttensor([[-91.]])\n",
      "-91\t49\ttensor([[-91.]])\n",
      "-91\t50\ttensor([[-91.]])\n",
      "-91\t51\ttensor([[-91.]])\n",
      "-91\t52\ttensor([[-91.]])\n",
      "-91\t53\ttensor([[-91.]])\n",
      "-91\t54\ttensor([[-91.]])\n",
      "-91\t55\ttensor([[-91.]])\n",
      "-91\t56\ttensor([[-91.]])\n",
      "-91\t57\ttensor([[-91.]])\n",
      "-91\t58\ttensor([[-91.]])\n",
      "-91\t59\ttensor([[-91.]])\n",
      "-91\t60\ttensor([[-91.]])\n",
      "-91\t61\ttensor([[-91.]])\n",
      "-91\t62\ttensor([[-91.]])\n",
      "-91\t63\ttensor([[-91.]])\n",
      "-91\t64\ttensor([[-91.]])\n",
      "-91\t65\ttensor([[-91.]])\n",
      "-91\t66\ttensor([[-91.]])\n",
      "-91\t67\ttensor([[-91.]])\n",
      "-91\t68\ttensor([[-91.]])\n",
      "-91\t69\ttensor([[-91.]])\n",
      "-91\t70\ttensor([[-91.]])\n",
      "-91\t71\ttensor([[-91.]])\n",
      "-91\t72\ttensor([[-91.]])\n",
      "-91\t73\ttensor([[-91.]])\n",
      "-91\t74\ttensor([[-91.]])\n",
      "-91\t75\ttensor([[-91.]])\n",
      "-91\t76\ttensor([[-91.]])\n",
      "-91\t77\ttensor([[-91.]])\n",
      "-91\t78\ttensor([[-91.]])\n",
      "-91\t79\ttensor([[-91.]])\n",
      "-91\t80\ttensor([[-91.]])\n",
      "-91\t81\ttensor([[-91.]])\n",
      "-91\t82\ttensor([[-91.]])\n",
      "-91\t83\ttensor([[-91.]])\n",
      "-91\t84\ttensor([[-91.]])\n",
      "-91\t85\ttensor([[-91.]])\n",
      "-91\t86\ttensor([[-91.]])\n",
      "-91\t87\ttensor([[-91.]])\n",
      "-91\t88\ttensor([[-91.]])\n",
      "-91\t89\ttensor([[-91.]])\n",
      "-91\t90\ttensor([[-91.]])\n",
      "-91\t91\ttensor([[-91.]])\n",
      "-91\t92\ttensor([[-91.]])\n",
      "-91\t93\ttensor([[-91.]])\n",
      "-91\t94\ttensor([[-91.]])\n",
      "-91\t95\ttensor([[-91.]])\n",
      "-91\t96\ttensor([[-91.]])\n",
      "-91\t97\ttensor([[-91.]])\n",
      "-91\t98\ttensor([[-91.]])\n",
      "-91\t99\ttensor([[-91.]])\n",
      "-90\t0\ttensor([[-90.]])\n",
      "-90\t1\ttensor([[-90.]])\n",
      "-90\t2\ttensor([[-90.]])\n",
      "-90\t3\ttensor([[-90.]])\n",
      "-90\t4\ttensor([[-90.]])\n",
      "-90\t5\ttensor([[-90.]])\n",
      "-90\t6\ttensor([[-90.]])\n",
      "-90\t7\ttensor([[-90.]])\n",
      "-90\t8\ttensor([[-90.]])\n",
      "-90\t9\ttensor([[-90.]])\n",
      "-90\t10\ttensor([[-90.]])\n",
      "-90\t11\ttensor([[-90.]])\n",
      "-90\t12\ttensor([[-90.]])\n",
      "-90\t13\ttensor([[-90.]])\n",
      "-90\t14\ttensor([[-90.]])\n",
      "-90\t15\ttensor([[-90.]])\n",
      "-90\t16\ttensor([[-90.]])\n",
      "-90\t17\ttensor([[-90.]])\n",
      "-90\t18\ttensor([[-90.]])\n",
      "-90\t19\ttensor([[-90.]])\n",
      "-90\t20\ttensor([[-90.]])\n",
      "-90\t21\ttensor([[-90.]])\n",
      "-90\t22\ttensor([[-90.]])\n",
      "-90\t23\ttensor([[-90.]])\n",
      "-90\t24\ttensor([[-90.]])\n",
      "-90\t25\ttensor([[-90.]])\n",
      "-90\t26\ttensor([[-90.]])\n",
      "-90\t27\ttensor([[-90.]])\n",
      "-90\t28\ttensor([[-90.]])\n",
      "-90\t29\ttensor([[-90.]])\n",
      "-90\t30\ttensor([[-90.]])\n",
      "-90\t31\ttensor([[-90.]])\n",
      "-90\t32\ttensor([[-90.]])\n",
      "-90\t33\ttensor([[-90.]])\n",
      "-90\t34\ttensor([[-90.]])\n",
      "-90\t35\ttensor([[-90.]])\n",
      "-90\t36\ttensor([[-90.]])\n",
      "-90\t37\ttensor([[-90.]])\n",
      "-90\t38\ttensor([[-90.]])\n",
      "-90\t39\ttensor([[-90.]])\n",
      "-90\t40\ttensor([[-90.]])\n",
      "-90\t41\ttensor([[-90.]])\n",
      "-90\t42\ttensor([[-90.]])\n",
      "-90\t43\ttensor([[-90.]])\n",
      "-90\t44\ttensor([[-90.]])\n",
      "-90\t45\ttensor([[-90.]])\n",
      "-90\t46\ttensor([[-90.]])\n",
      "-90\t47\ttensor([[-90.]])\n",
      "-90\t48\ttensor([[-90.]])\n",
      "-90\t49\ttensor([[-90.]])\n",
      "-90\t50\ttensor([[-90.]])\n",
      "-90\t51\ttensor([[-90.]])\n",
      "-90\t52\ttensor([[-90.]])\n",
      "-90\t53\ttensor([[-90.]])\n",
      "-90\t54\ttensor([[-90.]])\n",
      "-90\t55\ttensor([[-90.]])\n",
      "-90\t56\ttensor([[-90.]])\n",
      "-90\t57\ttensor([[-90.]])\n",
      "-90\t58\ttensor([[-90.]])\n",
      "-90\t59\ttensor([[-90.]])\n",
      "-90\t60\ttensor([[-90.]])\n",
      "-90\t61\ttensor([[-90.]])\n",
      "-90\t62\ttensor([[-90.]])\n",
      "-90\t63\ttensor([[-90.]])\n",
      "-90\t64\ttensor([[-90.]])\n",
      "-90\t65\ttensor([[-90.]])\n",
      "-90\t66\ttensor([[-90.]])\n",
      "-90\t67\ttensor([[-90.]])\n",
      "-90\t68\ttensor([[-90.]])\n",
      "-90\t69\ttensor([[-90.]])\n",
      "-90\t70\ttensor([[-90.]])\n",
      "-90\t71\ttensor([[-90.]])\n",
      "-90\t72\ttensor([[-90.]])\n",
      "-90\t73\ttensor([[-90.]])\n",
      "-90\t74\ttensor([[-90.]])\n",
      "-90\t75\ttensor([[-90.]])\n",
      "-90\t76\ttensor([[-90.]])\n",
      "-90\t77\ttensor([[-90.]])\n",
      "-90\t78\ttensor([[-90.]])\n",
      "-90\t79\ttensor([[-90.]])\n",
      "-90\t80\ttensor([[-90.]])\n",
      "-90\t81\ttensor([[-90.]])\n",
      "-90\t82\ttensor([[-90.]])\n",
      "-90\t83\ttensor([[-90.]])\n",
      "-90\t84\ttensor([[-90.]])\n",
      "-90\t85\ttensor([[-90.]])\n",
      "-90\t86\ttensor([[-90.]])\n",
      "-90\t87\ttensor([[-90.]])\n",
      "-90\t88\ttensor([[-90.]])\n",
      "-90\t89\ttensor([[-90.]])\n",
      "-90\t90\ttensor([[-90.]])\n",
      "-90\t91\ttensor([[-90.]])\n",
      "-90\t92\ttensor([[-90.]])\n",
      "-90\t93\ttensor([[-90.]])\n",
      "-90\t94\ttensor([[-90.]])\n",
      "-90\t95\ttensor([[-90.]])\n",
      "-90\t96\ttensor([[-90.]])\n",
      "-90\t97\ttensor([[-90.]])\n",
      "-90\t98\ttensor([[-90.]])\n",
      "-90\t99\ttensor([[-90.]])\n",
      "-89\t0\ttensor([[-89.]])\n",
      "-89\t1\ttensor([[-89.]])\n",
      "-89\t2\ttensor([[-89.]])\n",
      "-89\t3\ttensor([[-89.]])\n",
      "-89\t4\ttensor([[-89.]])\n",
      "-89\t5\ttensor([[-89.]])\n",
      "-89\t6\ttensor([[-89.]])\n",
      "-89\t7\ttensor([[-89.]])\n",
      "-89\t8\ttensor([[-89.]])\n",
      "-89\t9\ttensor([[-89.]])\n",
      "-89\t10\ttensor([[-89.]])\n",
      "-89\t11\ttensor([[-89.]])\n",
      "-89\t12\ttensor([[-89.]])\n",
      "-89\t13\ttensor([[-89.]])\n",
      "-89\t14\ttensor([[-89.]])\n",
      "-89\t15\ttensor([[-89.]])\n",
      "-89\t16\ttensor([[-89.]])\n",
      "-89\t17\ttensor([[-89.]])\n",
      "-89\t18\ttensor([[-89.]])\n",
      "-89\t19\ttensor([[-89.]])\n",
      "-89\t20\ttensor([[-89.]])\n",
      "-89\t21\ttensor([[-89.]])\n",
      "-89\t22\ttensor([[-89.]])\n",
      "-89\t23\ttensor([[-89.]])\n",
      "-89\t24\ttensor([[-89.]])\n",
      "-89\t25\ttensor([[-89.]])\n",
      "-89\t26\ttensor([[-89.]])\n",
      "-89\t27\ttensor([[-89.]])\n",
      "-89\t28\ttensor([[-89.]])\n",
      "-89\t29\ttensor([[-89.]])\n",
      "-89\t30\ttensor([[-89.]])\n",
      "-89\t31\ttensor([[-89.]])\n",
      "-89\t32\ttensor([[-89.]])\n",
      "-89\t33\ttensor([[-89.]])\n",
      "-89\t34\ttensor([[-89.]])\n",
      "-89\t35\ttensor([[-89.]])\n",
      "-89\t36\ttensor([[-89.]])\n",
      "-89\t37\ttensor([[-89.]])\n",
      "-89\t38\ttensor([[-89.]])\n",
      "-89\t39\ttensor([[-89.]])\n",
      "-89\t40\ttensor([[-89.]])\n",
      "-89\t41\ttensor([[-89.]])\n",
      "-89\t42\ttensor([[-89.]])\n",
      "-89\t43\ttensor([[-89.]])\n",
      "-89\t44\ttensor([[-89.]])\n",
      "-89\t45\ttensor([[-89.]])\n",
      "-89\t46\ttensor([[-89.]])\n",
      "-89\t47\ttensor([[-89.]])\n",
      "-89\t48\ttensor([[-89.]])\n",
      "-89\t49\ttensor([[-89.]])\n",
      "-89\t50\ttensor([[-89.]])\n",
      "-89\t51\ttensor([[-89.]])\n",
      "-89\t52\ttensor([[-89.]])\n",
      "-89\t53\ttensor([[-89.]])\n",
      "-89\t54\ttensor([[-89.]])\n",
      "-89\t55\ttensor([[-89.]])\n",
      "-89\t56\ttensor([[-89.]])\n",
      "-89\t57\ttensor([[-89.]])\n",
      "-89\t58\ttensor([[-89.]])\n",
      "-89\t59\ttensor([[-89.]])\n",
      "-89\t60\ttensor([[-89.]])\n",
      "-89\t61\ttensor([[-89.]])\n",
      "-89\t62\ttensor([[-89.]])\n",
      "-89\t63\ttensor([[-89.]])\n",
      "-89\t64\ttensor([[-89.]])\n",
      "-89\t65\ttensor([[-89.]])\n",
      "-89\t66\ttensor([[-89.]])\n",
      "-89\t67\ttensor([[-89.]])\n",
      "-89\t68\ttensor([[-89.]])\n",
      "-89\t69\ttensor([[-89.]])\n",
      "-89\t70\ttensor([[-89.]])\n",
      "-89\t71\ttensor([[-89.]])\n",
      "-89\t72\ttensor([[-89.]])\n",
      "-89\t73\ttensor([[-89.]])\n",
      "-89\t74\ttensor([[-89.]])\n",
      "-89\t75\ttensor([[-89.]])\n",
      "-89\t76\ttensor([[-89.]])\n",
      "-89\t77\ttensor([[-89.]])\n",
      "-89\t78\ttensor([[-89.]])\n",
      "-89\t79\ttensor([[-89.]])\n",
      "-89\t80\ttensor([[-89.]])\n",
      "-89\t81\ttensor([[-89.]])\n",
      "-89\t82\ttensor([[-89.]])\n",
      "-89\t83\ttensor([[-89.]])\n",
      "-89\t84\ttensor([[-89.]])\n",
      "-89\t85\ttensor([[-89.]])\n",
      "-89\t86\ttensor([[-89.]])\n",
      "-89\t87\ttensor([[-89.]])\n",
      "-89\t88\ttensor([[-89.]])\n",
      "-89\t89\ttensor([[-89.]])\n",
      "-89\t90\ttensor([[-89.]])\n",
      "-89\t91\ttensor([[-89.]])\n",
      "-89\t92\ttensor([[-89.]])\n",
      "-89\t93\ttensor([[-89.]])\n",
      "-89\t94\ttensor([[-89.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-89\t95\ttensor([[-89.]])\n",
      "-89\t96\ttensor([[-89.]])\n",
      "-89\t97\ttensor([[-89.]])\n",
      "-89\t98\ttensor([[-89.]])\n",
      "-89\t99\ttensor([[-89.]])\n",
      "-88\t0\ttensor([[-88.]])\n",
      "-88\t1\ttensor([[-88.]])\n",
      "-88\t2\ttensor([[-88.]])\n",
      "-88\t3\ttensor([[-88.]])\n",
      "-88\t4\ttensor([[-88.]])\n",
      "-88\t5\ttensor([[-88.]])\n",
      "-88\t6\ttensor([[-88.]])\n",
      "-88\t7\ttensor([[-88.]])\n",
      "-88\t8\ttensor([[-88.]])\n",
      "-88\t9\ttensor([[-88.]])\n",
      "-88\t10\ttensor([[-88.]])\n",
      "-88\t11\ttensor([[-88.]])\n",
      "-88\t12\ttensor([[-88.]])\n",
      "-88\t13\ttensor([[-88.]])\n",
      "-88\t14\ttensor([[-88.]])\n",
      "-88\t15\ttensor([[-88.]])\n",
      "-88\t16\ttensor([[-88.]])\n",
      "-88\t17\ttensor([[-88.]])\n",
      "-88\t18\ttensor([[-88.]])\n",
      "-88\t19\ttensor([[-88.]])\n",
      "-88\t20\ttensor([[-88.]])\n",
      "-88\t21\ttensor([[-88.]])\n",
      "-88\t22\ttensor([[-88.]])\n",
      "-88\t23\ttensor([[-88.]])\n",
      "-88\t24\ttensor([[-88.]])\n",
      "-88\t25\ttensor([[-88.]])\n",
      "-88\t26\ttensor([[-88.]])\n",
      "-88\t27\ttensor([[-88.]])\n",
      "-88\t28\ttensor([[-88.]])\n",
      "-88\t29\ttensor([[-88.]])\n",
      "-88\t30\ttensor([[-88.]])\n",
      "-88\t31\ttensor([[-88.]])\n",
      "-88\t32\ttensor([[-88.]])\n",
      "-88\t33\ttensor([[-88.]])\n",
      "-88\t34\ttensor([[-88.]])\n",
      "-88\t35\ttensor([[-88.]])\n",
      "-88\t36\ttensor([[-88.]])\n",
      "-88\t37\ttensor([[-88.]])\n",
      "-88\t38\ttensor([[-88.]])\n",
      "-88\t39\ttensor([[-88.]])\n",
      "-88\t40\ttensor([[-88.]])\n",
      "-88\t41\ttensor([[-88.]])\n",
      "-88\t42\ttensor([[-88.]])\n",
      "-88\t43\ttensor([[-88.]])\n",
      "-88\t44\ttensor([[-88.]])\n",
      "-88\t45\ttensor([[-88.]])\n",
      "-88\t46\ttensor([[-88.]])\n",
      "-88\t47\ttensor([[-88.]])\n",
      "-88\t48\ttensor([[-88.]])\n",
      "-88\t49\ttensor([[-88.]])\n",
      "-88\t50\ttensor([[-88.]])\n",
      "-88\t51\ttensor([[-88.]])\n",
      "-88\t52\ttensor([[-88.]])\n",
      "-88\t53\ttensor([[-88.]])\n",
      "-88\t54\ttensor([[-88.]])\n",
      "-88\t55\ttensor([[-88.]])\n",
      "-88\t56\ttensor([[-88.]])\n",
      "-88\t57\ttensor([[-88.]])\n",
      "-88\t58\ttensor([[-88.]])\n",
      "-88\t59\ttensor([[-88.]])\n",
      "-88\t60\ttensor([[-88.]])\n",
      "-88\t61\ttensor([[-88.]])\n",
      "-88\t62\ttensor([[-88.]])\n",
      "-88\t63\ttensor([[-88.]])\n",
      "-88\t64\ttensor([[-88.]])\n",
      "-88\t65\ttensor([[-88.]])\n",
      "-88\t66\ttensor([[-88.]])\n",
      "-88\t67\ttensor([[-88.]])\n",
      "-88\t68\ttensor([[-88.]])\n",
      "-88\t69\ttensor([[-88.]])\n",
      "-88\t70\ttensor([[-88.]])\n",
      "-88\t71\ttensor([[-88.]])\n",
      "-88\t72\ttensor([[-88.]])\n",
      "-88\t73\ttensor([[-88.]])\n",
      "-88\t74\ttensor([[-88.]])\n",
      "-88\t75\ttensor([[-88.]])\n",
      "-88\t76\ttensor([[-88.]])\n",
      "-88\t77\ttensor([[-88.]])\n",
      "-88\t78\ttensor([[-88.]])\n",
      "-88\t79\ttensor([[-88.]])\n",
      "-88\t80\ttensor([[-88.]])\n",
      "-88\t81\ttensor([[-88.]])\n",
      "-88\t82\ttensor([[-88.]])\n",
      "-88\t83\ttensor([[-88.]])\n",
      "-88\t84\ttensor([[-88.]])\n",
      "-88\t85\ttensor([[-88.]])\n",
      "-88\t86\ttensor([[-88.]])\n",
      "-88\t87\ttensor([[-88.]])\n",
      "-88\t88\ttensor([[-88.]])\n",
      "-88\t89\ttensor([[-88.]])\n",
      "-88\t90\ttensor([[-88.]])\n",
      "-88\t91\ttensor([[-88.]])\n",
      "-88\t92\ttensor([[-88.]])\n",
      "-88\t93\ttensor([[-88.]])\n",
      "-88\t94\ttensor([[-88.]])\n",
      "-88\t95\ttensor([[-88.]])\n",
      "-88\t96\ttensor([[-88.]])\n",
      "-88\t97\ttensor([[-88.]])\n",
      "-88\t98\ttensor([[-88.]])\n",
      "-88\t99\ttensor([[-88.]])\n",
      "-87\t0\ttensor([[-87.]])\n",
      "-87\t1\ttensor([[-87.]])\n",
      "-87\t2\ttensor([[-87.]])\n",
      "-87\t3\ttensor([[-87.]])\n",
      "-87\t4\ttensor([[-87.]])\n",
      "-87\t5\ttensor([[-87.]])\n",
      "-87\t6\ttensor([[-87.]])\n",
      "-87\t7\ttensor([[-87.]])\n",
      "-87\t8\ttensor([[-87.]])\n",
      "-87\t9\ttensor([[-87.]])\n",
      "-87\t10\ttensor([[-87.]])\n",
      "-87\t11\ttensor([[-87.]])\n",
      "-87\t12\ttensor([[-87.]])\n",
      "-87\t13\ttensor([[-87.]])\n",
      "-87\t14\ttensor([[-87.]])\n",
      "-87\t15\ttensor([[-87.]])\n",
      "-87\t16\ttensor([[-87.]])\n",
      "-87\t17\ttensor([[-87.]])\n",
      "-87\t18\ttensor([[-87.]])\n",
      "-87\t19\ttensor([[-87.]])\n",
      "-87\t20\ttensor([[-87.]])\n",
      "-87\t21\ttensor([[-87.]])\n",
      "-87\t22\ttensor([[-87.]])\n",
      "-87\t23\ttensor([[-87.]])\n",
      "-87\t24\ttensor([[-87.]])\n",
      "-87\t25\ttensor([[-87.]])\n",
      "-87\t26\ttensor([[-87.]])\n",
      "-87\t27\ttensor([[-87.]])\n",
      "-87\t28\ttensor([[-87.]])\n",
      "-87\t29\ttensor([[-87.]])\n",
      "-87\t30\ttensor([[-87.]])\n",
      "-87\t31\ttensor([[-87.]])\n",
      "-87\t32\ttensor([[-87.]])\n",
      "-87\t33\ttensor([[-87.]])\n",
      "-87\t34\ttensor([[-87.]])\n",
      "-87\t35\ttensor([[-87.]])\n",
      "-87\t36\ttensor([[-87.]])\n",
      "-87\t37\ttensor([[-87.]])\n",
      "-87\t38\ttensor([[-87.]])\n",
      "-87\t39\ttensor([[-87.]])\n",
      "-87\t40\ttensor([[-87.]])\n",
      "-87\t41\ttensor([[-87.]])\n",
      "-87\t42\ttensor([[-87.]])\n",
      "-87\t43\ttensor([[-87.]])\n",
      "-87\t44\ttensor([[-87.]])\n",
      "-87\t45\ttensor([[-87.]])\n",
      "-87\t46\ttensor([[-87.]])\n",
      "-87\t47\ttensor([[-87.]])\n",
      "-87\t48\ttensor([[-87.]])\n",
      "-87\t49\ttensor([[-87.]])\n",
      "-87\t50\ttensor([[-87.]])\n",
      "-87\t51\ttensor([[-87.]])\n",
      "-87\t52\ttensor([[-87.]])\n",
      "-87\t53\ttensor([[-87.]])\n",
      "-87\t54\ttensor([[-87.]])\n",
      "-87\t55\ttensor([[-87.]])\n",
      "-87\t56\ttensor([[-87.]])\n",
      "-87\t57\ttensor([[-87.]])\n",
      "-87\t58\ttensor([[-87.]])\n",
      "-87\t59\ttensor([[-87.]])\n",
      "-87\t60\ttensor([[-87.]])\n",
      "-87\t61\ttensor([[-87.]])\n",
      "-87\t62\ttensor([[-87.]])\n",
      "-87\t63\ttensor([[-87.]])\n",
      "-87\t64\ttensor([[-87.]])\n",
      "-87\t65\ttensor([[-87.]])\n",
      "-87\t66\ttensor([[-87.]])\n",
      "-87\t67\ttensor([[-87.]])\n",
      "-87\t68\ttensor([[-87.]])\n",
      "-87\t69\ttensor([[-87.]])\n",
      "-87\t70\ttensor([[-87.]])\n",
      "-87\t71\ttensor([[-87.]])\n",
      "-87\t72\ttensor([[-87.]])\n",
      "-87\t73\ttensor([[-87.]])\n",
      "-87\t74\ttensor([[-87.]])\n",
      "-87\t75\ttensor([[-87.]])\n",
      "-87\t76\ttensor([[-87.]])\n",
      "-87\t77\ttensor([[-87.]])\n",
      "-87\t78\ttensor([[-87.]])\n",
      "-87\t79\ttensor([[-87.]])\n",
      "-87\t80\ttensor([[-87.]])\n",
      "-87\t81\ttensor([[-87.]])\n",
      "-87\t82\ttensor([[-87.]])\n",
      "-87\t83\ttensor([[-87.]])\n",
      "-87\t84\ttensor([[-87.]])\n",
      "-87\t85\ttensor([[-87.]])\n",
      "-87\t86\ttensor([[-87.]])\n",
      "-87\t87\ttensor([[-87.]])\n",
      "-87\t88\ttensor([[-87.]])\n",
      "-87\t89\ttensor([[-87.]])\n",
      "-87\t90\ttensor([[-87.]])\n",
      "-87\t91\ttensor([[-87.]])\n",
      "-87\t92\ttensor([[-87.]])\n",
      "-87\t93\ttensor([[-87.]])\n",
      "-87\t94\ttensor([[-87.]])\n",
      "-87\t95\ttensor([[-87.]])\n",
      "-87\t96\ttensor([[-87.]])\n",
      "-87\t97\ttensor([[-87.]])\n",
      "-87\t98\ttensor([[-87.]])\n",
      "-87\t99\ttensor([[-87.]])\n",
      "-86\t0\ttensor([[-86.]])\n",
      "-86\t1\ttensor([[-86.]])\n",
      "-86\t2\ttensor([[-86.]])\n",
      "-86\t3\ttensor([[-86.]])\n",
      "-86\t4\ttensor([[-86.]])\n",
      "-86\t5\ttensor([[-86.]])\n",
      "-86\t6\ttensor([[-86.]])\n",
      "-86\t7\ttensor([[-86.]])\n",
      "-86\t8\ttensor([[-86.]])\n",
      "-86\t9\ttensor([[-86.]])\n",
      "-86\t10\ttensor([[-86.]])\n",
      "-86\t11\ttensor([[-86.]])\n",
      "-86\t12\ttensor([[-86.]])\n",
      "-86\t13\ttensor([[-86.]])\n",
      "-86\t14\ttensor([[-86.]])\n",
      "-86\t15\ttensor([[-86.]])\n",
      "-86\t16\ttensor([[-86.]])\n",
      "-86\t17\ttensor([[-86.]])\n",
      "-86\t18\ttensor([[-86.]])\n",
      "-86\t19\ttensor([[-86.]])\n",
      "-86\t20\ttensor([[-86.]])\n",
      "-86\t21\ttensor([[-86.]])\n",
      "-86\t22\ttensor([[-86.]])\n",
      "-86\t23\ttensor([[-86.]])\n",
      "-86\t24\ttensor([[-86.]])\n",
      "-86\t25\ttensor([[-86.]])\n",
      "-86\t26\ttensor([[-86.]])\n",
      "-86\t27\ttensor([[-86.]])\n",
      "-86\t28\ttensor([[-86.]])\n",
      "-86\t29\ttensor([[-86.]])\n",
      "-86\t30\ttensor([[-86.]])\n",
      "-86\t31\ttensor([[-86.]])\n",
      "-86\t32\ttensor([[-86.]])\n",
      "-86\t33\ttensor([[-86.]])\n",
      "-86\t34\ttensor([[-86.]])\n",
      "-86\t35\ttensor([[-86.]])\n",
      "-86\t36\ttensor([[-86.]])\n",
      "-86\t37\ttensor([[-86.]])\n",
      "-86\t38\ttensor([[-86.]])\n",
      "-86\t39\ttensor([[-86.]])\n",
      "-86\t40\ttensor([[-86.]])\n",
      "-86\t41\ttensor([[-86.]])\n",
      "-86\t42\ttensor([[-86.]])\n",
      "-86\t43\ttensor([[-86.]])\n",
      "-86\t44\ttensor([[-86.]])\n",
      "-86\t45\ttensor([[-86.]])\n",
      "-86\t46\ttensor([[-86.]])\n",
      "-86\t47\ttensor([[-86.]])\n",
      "-86\t48\ttensor([[-86.]])\n",
      "-86\t49\ttensor([[-86.]])\n",
      "-86\t50\ttensor([[-86.]])\n",
      "-86\t51\ttensor([[-86.]])\n",
      "-86\t52\ttensor([[-86.]])\n",
      "-86\t53\ttensor([[-86.]])\n",
      "-86\t54\ttensor([[-86.]])\n",
      "-86\t55\ttensor([[-86.]])\n",
      "-86\t56\ttensor([[-86.]])\n",
      "-86\t57\ttensor([[-86.]])\n",
      "-86\t58\ttensor([[-86.]])\n",
      "-86\t59\ttensor([[-86.]])\n",
      "-86\t60\ttensor([[-86.]])\n",
      "-86\t61\ttensor([[-86.]])\n",
      "-86\t62\ttensor([[-86.]])\n",
      "-86\t63\ttensor([[-86.]])\n",
      "-86\t64\ttensor([[-86.]])\n",
      "-86\t65\ttensor([[-86.]])\n",
      "-86\t66\ttensor([[-86.]])\n",
      "-86\t67\ttensor([[-86.]])\n",
      "-86\t68\ttensor([[-86.]])\n",
      "-86\t69\ttensor([[-86.]])\n",
      "-86\t70\ttensor([[-86.]])\n",
      "-86\t71\ttensor([[-86.]])\n",
      "-86\t72\ttensor([[-86.]])\n",
      "-86\t73\ttensor([[-86.]])\n",
      "-86\t74\ttensor([[-86.]])\n",
      "-86\t75\ttensor([[-86.]])\n",
      "-86\t76\ttensor([[-86.]])\n",
      "-86\t77\ttensor([[-86.]])\n",
      "-86\t78\ttensor([[-86.]])\n",
      "-86\t79\ttensor([[-86.]])\n",
      "-86\t80\ttensor([[-86.]])\n",
      "-86\t81\ttensor([[-86.]])\n",
      "-86\t82\ttensor([[-86.]])\n",
      "-86\t83\ttensor([[-86.]])\n",
      "-86\t84\ttensor([[-86.]])\n",
      "-86\t85\ttensor([[-86.]])\n",
      "-86\t86\ttensor([[-86.]])\n",
      "-86\t87\ttensor([[-86.]])\n",
      "-86\t88\ttensor([[-86.]])\n",
      "-86\t89\ttensor([[-86.]])\n",
      "-86\t90\ttensor([[-86.]])\n",
      "-86\t91\ttensor([[-86.]])\n",
      "-86\t92\ttensor([[-86.]])\n",
      "-86\t93\ttensor([[-86.]])\n",
      "-86\t94\ttensor([[-86.]])\n",
      "-86\t95\ttensor([[-86.]])\n",
      "-86\t96\ttensor([[-86.]])\n",
      "-86\t97\ttensor([[-86.]])\n",
      "-86\t98\ttensor([[-86.]])\n",
      "-86\t99\ttensor([[-86.]])\n",
      "-85\t0\ttensor([[-85.]])\n",
      "-85\t1\ttensor([[-85.]])\n",
      "-85\t2\ttensor([[-85.]])\n",
      "-85\t3\ttensor([[-85.]])\n",
      "-85\t4\ttensor([[-85.]])\n",
      "-85\t5\ttensor([[-85.]])\n",
      "-85\t6\ttensor([[-85.]])\n",
      "-85\t7\ttensor([[-85.]])\n",
      "-85\t8\ttensor([[-85.]])\n",
      "-85\t9\ttensor([[-85.]])\n",
      "-85\t10\ttensor([[-85.]])\n",
      "-85\t11\ttensor([[-85.]])\n",
      "-85\t12\ttensor([[-85.]])\n",
      "-85\t13\ttensor([[-85.]])\n",
      "-85\t14\ttensor([[-85.]])\n",
      "-85\t15\ttensor([[-85.]])\n",
      "-85\t16\ttensor([[-85.]])\n",
      "-85\t17\ttensor([[-85.]])\n",
      "-85\t18\ttensor([[-85.]])\n",
      "-85\t19\ttensor([[-85.]])\n",
      "-85\t20\ttensor([[-85.]])\n",
      "-85\t21\ttensor([[-85.]])\n",
      "-85\t22\ttensor([[-85.]])\n",
      "-85\t23\ttensor([[-85.]])\n",
      "-85\t24\ttensor([[-85.]])\n",
      "-85\t25\ttensor([[-85.]])\n",
      "-85\t26\ttensor([[-85.]])\n",
      "-85\t27\ttensor([[-85.]])\n",
      "-85\t28\ttensor([[-85.]])\n",
      "-85\t29\ttensor([[-85.]])\n",
      "-85\t30\ttensor([[-85.]])\n",
      "-85\t31\ttensor([[-85.]])\n",
      "-85\t32\ttensor([[-85.]])\n",
      "-85\t33\ttensor([[-85.]])\n",
      "-85\t34\ttensor([[-85.]])\n",
      "-85\t35\ttensor([[-85.]])\n",
      "-85\t36\ttensor([[-85.]])\n",
      "-85\t37\ttensor([[-85.]])\n",
      "-85\t38\ttensor([[-85.]])\n",
      "-85\t39\ttensor([[-85.]])\n",
      "-85\t40\ttensor([[-85.]])\n",
      "-85\t41\ttensor([[-85.]])\n",
      "-85\t42\ttensor([[-85.]])\n",
      "-85\t43\ttensor([[-85.]])\n",
      "-85\t44\ttensor([[-85.]])\n",
      "-85\t45\ttensor([[-85.]])\n",
      "-85\t46\ttensor([[-85.]])\n",
      "-85\t47\ttensor([[-85.]])\n",
      "-85\t48\ttensor([[-85.]])\n",
      "-85\t49\ttensor([[-85.]])\n",
      "-85\t50\ttensor([[-85.]])\n",
      "-85\t51\ttensor([[-85.]])\n",
      "-85\t52\ttensor([[-85.]])\n",
      "-85\t53\ttensor([[-85.]])\n",
      "-85\t54\ttensor([[-85.]])\n",
      "-85\t55\ttensor([[-85.]])\n",
      "-85\t56\ttensor([[-85.]])\n",
      "-85\t57\ttensor([[-85.]])\n",
      "-85\t58\ttensor([[-85.]])\n",
      "-85\t59\ttensor([[-85.]])\n",
      "-85\t60\ttensor([[-85.]])\n",
      "-85\t61\ttensor([[-85.]])\n",
      "-85\t62\ttensor([[-85.]])\n",
      "-85\t63\ttensor([[-85.]])\n",
      "-85\t64\ttensor([[-85.]])\n",
      "-85\t65\ttensor([[-85.]])\n",
      "-85\t66\ttensor([[-85.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-85\t67\ttensor([[-85.]])\n",
      "-85\t68\ttensor([[-85.]])\n",
      "-85\t69\ttensor([[-85.]])\n",
      "-85\t70\ttensor([[-85.]])\n",
      "-85\t71\ttensor([[-85.]])\n",
      "-85\t72\ttensor([[-85.]])\n",
      "-85\t73\ttensor([[-85.]])\n",
      "-85\t74\ttensor([[-85.]])\n",
      "-85\t75\ttensor([[-85.]])\n",
      "-85\t76\ttensor([[-85.]])\n",
      "-85\t77\ttensor([[-85.]])\n",
      "-85\t78\ttensor([[-85.]])\n",
      "-85\t79\ttensor([[-85.]])\n",
      "-85\t80\ttensor([[-85.]])\n",
      "-85\t81\ttensor([[-85.]])\n",
      "-85\t82\ttensor([[-85.]])\n",
      "-85\t83\ttensor([[-85.]])\n",
      "-85\t84\ttensor([[-85.]])\n",
      "-85\t85\ttensor([[-85.]])\n",
      "-85\t86\ttensor([[-85.]])\n",
      "-85\t87\ttensor([[-85.]])\n",
      "-85\t88\ttensor([[-85.]])\n",
      "-85\t89\ttensor([[-85.]])\n",
      "-85\t90\ttensor([[-85.]])\n",
      "-85\t91\ttensor([[-85.]])\n",
      "-85\t92\ttensor([[-85.]])\n",
      "-85\t93\ttensor([[-85.]])\n",
      "-85\t94\ttensor([[-85.]])\n",
      "-85\t95\ttensor([[-85.]])\n",
      "-85\t96\ttensor([[-85.]])\n",
      "-85\t97\ttensor([[-85.]])\n",
      "-85\t98\ttensor([[-85.]])\n",
      "-85\t99\ttensor([[-85.]])\n",
      "-84\t0\ttensor([[-84.]])\n",
      "-84\t1\ttensor([[-84.]])\n",
      "-84\t2\ttensor([[-84.]])\n",
      "-84\t3\ttensor([[-84.]])\n",
      "-84\t4\ttensor([[-84.]])\n",
      "-84\t5\ttensor([[-84.]])\n",
      "-84\t6\ttensor([[-84.]])\n",
      "-84\t7\ttensor([[-84.]])\n",
      "-84\t8\ttensor([[-84.]])\n",
      "-84\t9\ttensor([[-84.]])\n",
      "-84\t10\ttensor([[-84.]])\n",
      "-84\t11\ttensor([[-84.]])\n",
      "-84\t12\ttensor([[-84.]])\n",
      "-84\t13\ttensor([[-84.]])\n",
      "-84\t14\ttensor([[-84.]])\n",
      "-84\t15\ttensor([[-84.]])\n",
      "-84\t16\ttensor([[-84.]])\n",
      "-84\t17\ttensor([[-84.]])\n",
      "-84\t18\ttensor([[-84.]])\n",
      "-84\t19\ttensor([[-84.]])\n",
      "-84\t20\ttensor([[-84.]])\n",
      "-84\t21\ttensor([[-84.]])\n",
      "-84\t22\ttensor([[-84.]])\n",
      "-84\t23\ttensor([[-84.]])\n",
      "-84\t24\ttensor([[-84.]])\n",
      "-84\t25\ttensor([[-84.]])\n",
      "-84\t26\ttensor([[-84.]])\n",
      "-84\t27\ttensor([[-84.]])\n",
      "-84\t28\ttensor([[-84.]])\n",
      "-84\t29\ttensor([[-84.]])\n",
      "-84\t30\ttensor([[-84.]])\n",
      "-84\t31\ttensor([[-84.]])\n",
      "-84\t32\ttensor([[-84.]])\n",
      "-84\t33\ttensor([[-84.]])\n",
      "-84\t34\ttensor([[-84.]])\n",
      "-84\t35\ttensor([[-84.]])\n",
      "-84\t36\ttensor([[-84.]])\n",
      "-84\t37\ttensor([[-84.]])\n",
      "-84\t38\ttensor([[-84.]])\n",
      "-84\t39\ttensor([[-84.]])\n",
      "-84\t40\ttensor([[-84.]])\n",
      "-84\t41\ttensor([[-84.]])\n",
      "-84\t42\ttensor([[-84.]])\n",
      "-84\t43\ttensor([[-84.]])\n",
      "-84\t44\ttensor([[-84.]])\n",
      "-84\t45\ttensor([[-84.]])\n",
      "-84\t46\ttensor([[-84.]])\n",
      "-84\t47\ttensor([[-84.]])\n",
      "-84\t48\ttensor([[-84.]])\n",
      "-84\t49\ttensor([[-84.]])\n",
      "-84\t50\ttensor([[-84.]])\n",
      "-84\t51\ttensor([[-84.]])\n",
      "-84\t52\ttensor([[-84.]])\n",
      "-84\t53\ttensor([[-84.]])\n",
      "-84\t54\ttensor([[-84.]])\n",
      "-84\t55\ttensor([[-84.]])\n",
      "-84\t56\ttensor([[-84.]])\n",
      "-84\t57\ttensor([[-84.]])\n",
      "-84\t58\ttensor([[-84.]])\n",
      "-84\t59\ttensor([[-84.]])\n",
      "-84\t60\ttensor([[-84.]])\n",
      "-84\t61\ttensor([[-84.]])\n",
      "-84\t62\ttensor([[-84.]])\n",
      "-84\t63\ttensor([[-84.]])\n",
      "-84\t64\ttensor([[-84.]])\n",
      "-84\t65\ttensor([[-84.]])\n",
      "-84\t66\ttensor([[-84.]])\n",
      "-84\t67\ttensor([[-84.]])\n",
      "-84\t68\ttensor([[-84.]])\n",
      "-84\t69\ttensor([[-84.]])\n",
      "-84\t70\ttensor([[-84.]])\n",
      "-84\t71\ttensor([[-84.]])\n",
      "-84\t72\ttensor([[-84.]])\n",
      "-84\t73\ttensor([[-84.]])\n",
      "-84\t74\ttensor([[-84.]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-cd8972ced9fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(t, loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/polo/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/polo/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(-100,100):\n",
    "    for _ in range(100):\n",
    "        i = float(t)\n",
    "        data_in = torch.tensor([[float(i),float(i),float(i)]])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(data_in)\n",
    "        \n",
    "        target = torch.tensor([[float(i)]])\n",
    "        print(\"{}\\t{}\\t{}\".format(t, _, target))\n",
    "        loss = loss_func(pred, target)\n",
    "#         print(t, loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0118]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "num = 99.0\n",
    "print(net(torch.tensor([[num,num,num]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = torch.tensor([[-100.0, -100.0, -100.0]])\n",
    "for i in range(-99, 100):\n",
    "    d = float(i)\n",
    "    data_in = torch.cat((data_in, torch.tensor([[d,d,d]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[-100.0]])\n",
    "for i in range(-99, 100):\n",
    "    d = float(i)\n",
    "    targets = torch.cat((targets, torch.tensor([[d]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueNet(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=16, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValueNet(env.observation_space.shape[0], HIDDEN_LAYER, env.action_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-0987936bf13d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     data_in = torch.tensor([[float(i),float(i),float(i)]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     print(\"{}\\t{}\\t{}\".format(_, targets))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(10000):\n",
    "#     i = float(t)\n",
    "#     data_in = torch.tensor([[float(i),float(i),float(i)]])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    preds = net(data_in)\n",
    "#     print(\"{}\\t{}\\t{}\".format(_, targets))\n",
    "#     target = torch.tensor([[float(i)]])\n",
    "    loss = loss_func(preds, targets)\n",
    "    print(loss)\n",
    "#         print(t, loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 3])\n",
      "torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "print(data_in.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-32.7767]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "num = -33.0\n",
    "print(net(torch.tensor([[num,num,num]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden, output_dim):\n",
    "        super(ValueNet, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POLO(object):\n",
    "    def __init__(self, K, T, lambda_, noise_mu, noise_sigma, U, u_init, memory_size, \n",
    "                 observation_space, action_space, state_space, net_hidden_layers, num_nets, gamma, \n",
    "                 state_samples, gradient_steps, noise_gaussian=True):\n",
    "        self.memory_size = memory_size\n",
    "        self.obs_mem = np.zeros((self.memory_size, observation_space))\n",
    "        self.state_mem = np.zeros((self.memory_size, state_space))\n",
    "        \n",
    "        self.K = K  # N_SAMPLES\n",
    "        self.T = T  # TIMESTEPS\n",
    "        self.lambda_ = lambda_\n",
    "        self.noise_mu = noise_mu\n",
    "        self.noise_sigma = noise_sigma\n",
    "        self.U = U\n",
    "        self.u_init = u_init\n",
    "        self.reward_total = np.zeros(shape=(self.K))\n",
    "        self.gamma = gamma\n",
    "        self.state_samples = state_samples\n",
    "        self.gradient_steps = gradient_steps\n",
    "\n",
    "\n",
    "        if noise_gaussian:\n",
    "            self.noise = np.random.normal(loc=self.noise_mu, scale=self.noise_sigma, size=(self.K, self.T))\n",
    "        else:\n",
    "            self.noise = np.full(shape=(self.K, self.T), fill_value=0.9)\n",
    "        \n",
    "        self.num_nets = num_nets\n",
    "        \n",
    "        self._build_value_nets(observation_space, net_hidden_layers, action_space)\n",
    "\n",
    "    \n",
    "    def _build_value_nets(self, input_dim, hidden, output_dim):\n",
    "        self.value_nets = []\n",
    "        self.loss_funcs = []\n",
    "        self.optimizers = []\n",
    "        \n",
    "        for i in range(self.num_nets):\n",
    "            self.value_nets.append(ValueNet(input_dim, hidden, output_dim))\n",
    "            self.loss_funcs.append(nn.MSELoss())\n",
    "            self.optimizers.append(torch.optim.Adam(self.value_nets[-1].parameters()))\n",
    "            \n",
    "        \n",
    "    def get_aggregated_value(self, s):\n",
    "        values = []\n",
    "        for net in self.value_nets:\n",
    "            values.append(net(torch.tensor(s, dtype=torch.float)).item())\n",
    "            \n",
    "        values = np.array(values)\n",
    "        weights = softmax(values)\n",
    "        weighted_values = values * weights\n",
    "\n",
    "        return sum(weighted_values)\n",
    "        \n",
    "    def learn(self, env):\n",
    "        init_state = env.env.state\n",
    "        for _ in range(self.gradient_steps):\n",
    "            idx = np.random.choice(np.min([self.memory_counter, self.memory_size]), size=self.state_samples, replace=False)\n",
    "\n",
    "            sampled_states = self.state_mem[idx,:]\n",
    "\n",
    "            sampled_obs = self.obs_mem[idx,:]\n",
    "\n",
    "\n",
    "\n",
    "            targets = x = [None for i in range(self.num_nets)]\n",
    "\n",
    "\n",
    "            for s_state, o in zip(sampled_states, sampled_obs):\n",
    "                discount = 1\n",
    "                total_reward = 0\n",
    "\n",
    "                max_rewards = [float('-inf') for _ in range(self.num_nets)]\n",
    "\n",
    "                for k in range(self.K):\n",
    "                    env.env.state = s_state\n",
    "                    for t in range(self.T):\n",
    "                        perturbed_action_t = self.U[t] + self.noise[k, t]\n",
    "\n",
    "                        s, reward, _, _ = env.step([perturbed_action_t])\n",
    "\n",
    "                        total_reward += discount * reward\n",
    "                        discount *= self.gamma\n",
    "\n",
    "                    for i in range(self.num_nets):\n",
    "                        net = self.value_nets[i]\n",
    "                        reward_for_net = torch.tensor(total_reward, dtype=torch.float) + net(torch.tensor(s, dtype=torch.float))\n",
    "                        if reward_for_net > max_rewards[i]:\n",
    "                            max_rewards[i] = reward_for_net\n",
    "\n",
    "\n",
    "\n",
    "                for i in range(self.num_nets):\n",
    "                    net = self.value_nets[i]\n",
    "                    loss_func = self.loss_funcs[i]\n",
    "                    optimizer = self.optimizers[i]\n",
    "\n",
    "                    target = max_rewards[i]\n",
    "\n",
    "                    if targets[i] is None:\n",
    "                        targets[i] = torch.tensor([[target]], dtype=torch.float)\n",
    "                    else:\n",
    "                        targets[i] = torch.cat((targets[i], torch.tensor([[target]], dtype=torch.float)))\n",
    "\n",
    "        env.env.state = init_state\n",
    "        \n",
    "\n",
    "        for i in range(self.num_nets):\n",
    "            net = self.value_nets[i]\n",
    "            loss_func = self.loss_funcs[i]\n",
    "            optimizer = self.optimizers[i]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            preds = net(torch.tensor(sampled_obs, dtype=torch.float))\n",
    "            \n",
    "            loss = loss_func(preds, targets[i])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    \n",
    "    def _compute_total_reward(self, k, env):\n",
    "        discount = 1\n",
    "        for t in range(self.T):\n",
    "            perturbed_action_t = self.U[t] + self.noise[k, t]\n",
    "            s, reward, _, _ = env.step([perturbed_action_t])\n",
    "            self.reward_total[k] += discount * reward\n",
    "            discount *= self.gamma\n",
    "        self.reward_total[k] += discount * self.get_aggregated_value(s)\n",
    "    \n",
    "    def _ensure_non_zero(self, reward, beta, factor):\n",
    "        return np.exp(-factor * (beta - reward))\n",
    "    \n",
    "    def choose_action(self, env):\n",
    "        init = env.env.state\n",
    "        for k in range(self.K):\n",
    "            self._compute_total_reward(k, env)\n",
    "            env.env.state = init\n",
    "        \n",
    "        beta = np.max(self.reward_total)  # maximize reward of all trajectories\n",
    "        reward_total_non_zero = self._ensure_non_zero(reward=self.reward_total, beta=beta, factor=1/self.lambda_)\n",
    "\n",
    "        eta = np.sum(reward_total_non_zero)\n",
    "        omega = 1/eta * reward_total_non_zero\n",
    "\n",
    "        self.U += [np.sum(omega * self.noise[:, t]) for t in range(self.T)]\n",
    "        \n",
    "        \n",
    "        env.env.state = init\n",
    "        action = self.U[0]\n",
    "        \n",
    "        self.U = np.roll(self.U, -1)  # shift all elements to the left\n",
    "        self.U[-1] = self.u_init  #\n",
    "        self.reward_total[:] = 0\n",
    "        \n",
    "        \n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def store_state(self, obs, state):\n",
    "        if not hasattr(self, 'memory_counter'):\n",
    "            self.memory_counter = 0\n",
    "\n",
    "        # replace the old memory with new memory\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.obs_mem[index] = np.array(obs)\n",
    "        self.state_mem[index] = np.array(state)\n",
    "\n",
    "        self.memory_counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action taken: -0.68 reward received: -1.09\n",
      "action taken: 0.21 reward received: -0.98\n",
      "action taken: -0.73 reward received: -1.00\n",
      "action taken: -0.44 reward received: -1.13\n",
      "action taken: 1.07 reward received: -1.40\n",
      "action taken: 1.07 reward received: -1.95\n",
      "action taken: -1.52 reward received: -2.79\n",
      "action taken: -2.10 reward received: -3.65\n",
      "action taken: 1.80 reward received: -4.64\n",
      "action taken: 1.37 reward received: -6.49\n",
      "action taken: -1.83 reward received: -8.72\n",
      "action taken: -0.86 reward received: -10.59\n",
      "action taken: 0.15 reward received: -12.70\n",
      "action taken: -0.12 reward received: -13.60\n",
      "action taken: -0.07 reward received: -11.59\n",
      "action taken: 0.01 reward received: -9.58\n",
      "action taken: 0.16 reward received: -7.69\n",
      "action taken: 0.28 reward received: -6.02\n",
      "action taken: 0.41 reward received: -4.61\n",
      "action taken: 0.53 reward received: -3.48\n",
      "action taken: 0.65 reward received: -2.61\n",
      "action taken: 0.77 reward received: -1.97\n",
      "action taken: 0.88 reward received: -1.51\n",
      "action taken: 0.98 reward received: -1.21\n",
      "action taken: 1.08 reward received: -1.02\n",
      "action taken: 1.17 reward received: -0.93\n",
      "action taken: 1.20 reward received: -0.92\n",
      "action taken: 1.21 reward received: -1.00\n",
      "action taken: 1.21 reward received: -1.16\n",
      "action taken: 1.13 reward received: -1.42\n",
      "action taken: 1.03 reward received: -1.80\n",
      "action taken: 0.91 reward received: -2.35\n",
      "action taken: 0.73 reward received: -3.10\n",
      "action taken: 0.58 reward received: -4.10\n",
      "action taken: 0.41 reward received: -5.40\n",
      "action taken: 0.28 reward received: -7.01\n",
      "action taken: 0.17 reward received: -8.91\n",
      "action taken: 0.15 reward received: -11.02\n",
      "action taken: 0.10 reward received: -13.21\n",
      "action taken: 0.12 reward received: -12.76\n",
      "action taken: 0.06 reward received: -10.80\n",
      "action taken: -0.03 reward received: -8.88\n",
      "action taken: -0.16 reward received: -7.10\n",
      "action taken: -0.30 reward received: -5.55\n",
      "action taken: -0.45 reward received: -4.26\n",
      "action taken: -0.59 reward received: -3.24\n",
      "action taken: -0.72 reward received: -2.47\n",
      "action taken: -0.84 reward received: -1.92\n",
      "action taken: -0.95 reward received: -1.53\n",
      "action taken: -1.05 reward received: -1.29\n",
      "action taken: -1.13 reward received: -1.18\n",
      "action taken: -1.16 reward received: -1.16\n",
      "action taken: -1.12 reward received: -1.25\n",
      "action taken: -1.07 reward received: -1.44\n",
      "action taken: -0.95 reward received: -1.76\n",
      "action taken: -0.83 reward received: -2.25\n",
      "action taken: -0.71 reward received: -2.92\n",
      "action taken: -0.61 reward received: -3.84\n",
      "action taken: -0.49 reward received: -5.03\n",
      "action taken: -0.42 reward received: -6.51\n",
      "action taken: -0.32 reward received: -8.27\n",
      "action taken: -0.20 reward received: -10.24\n",
      "action taken: -0.13 reward received: -12.33\n",
      "action taken: -0.08 reward received: -13.10\n",
      "action taken: 0.01 reward received: -11.22\n",
      "action taken: 0.13 reward received: -9.35\n",
      "action taken: 0.25 reward received: -7.59\n",
      "action taken: 0.38 reward received: -6.02\n",
      "action taken: 0.51 reward received: -4.68\n",
      "action taken: 0.63 reward received: -3.61\n",
      "action taken: 0.75 reward received: -2.78\n",
      "action taken: 0.86 reward received: -2.17\n",
      "action taken: 0.97 reward received: -1.74\n",
      "action taken: 1.07 reward received: -1.47\n",
      "action taken: 1.13 reward received: -1.33\n",
      "action taken: 1.17 reward received: -1.30\n",
      "action taken: 1.17 reward received: -1.38\n",
      "action taken: 1.12 reward received: -1.58\n",
      "action taken: 1.04 reward received: -1.91\n",
      "action taken: 0.91 reward received: -2.41\n",
      "action taken: 0.75 reward received: -3.10\n",
      "action taken: 0.58 reward received: -4.03\n",
      "action taken: 0.40 reward received: -5.23\n",
      "action taken: 0.26 reward received: -6.74\n",
      "action taken: 0.13 reward received: -8.52\n",
      "action taken: 0.06 reward received: -10.52\n",
      "action taken: 0.06 reward received: -12.62\n",
      "action taken: 0.07 reward received: -12.72\n",
      "action taken: 0.01 reward received: -10.85\n",
      "action taken: -0.08 reward received: -9.01\n",
      "action taken: -0.21 reward received: -7.28\n",
      "action taken: -0.35 reward received: -5.76\n",
      "action taken: -0.49 reward received: -4.48\n",
      "action taken: -0.63 reward received: -3.47\n",
      "action taken: -0.76 reward received: -2.69\n",
      "action taken: -0.88 reward received: -2.13\n",
      "action taken: -0.98 reward received: -1.74\n",
      "action taken: -1.07 reward received: -1.51\n",
      "action taken: -1.10 reward received: -1.41\n",
      "action taken: -1.07 reward received: -1.44\n",
      "action taken: -1.02 reward received: -1.58\n",
      "action taken: -0.91 reward received: -1.86\n",
      "action taken: -0.78 reward received: -2.31\n",
      "action taken: -0.67 reward received: -2.95\n",
      "action taken: -0.57 reward received: -3.82\n",
      "action taken: -0.45 reward received: -4.96\n",
      "action taken: -0.39 reward received: -6.39\n",
      "action taken: -0.29 reward received: -8.08\n",
      "action taken: -0.16 reward received: -9.99\n",
      "action taken: -0.10 reward received: -12.02\n",
      "action taken: -0.04 reward received: -13.03\n",
      "action taken: 0.05 reward received: -11.20\n",
      "action taken: 0.16 reward received: -9.39\n",
      "action taken: 0.28 reward received: -7.67\n",
      "action taken: 0.41 reward received: -6.12\n",
      "action taken: 0.53 reward received: -4.80\n",
      "action taken: 0.65 reward received: -3.73\n",
      "action taken: 0.77 reward received: -2.90\n",
      "action taken: 0.88 reward received: -2.29\n",
      "action taken: 0.98 reward received: -1.87\n",
      "action taken: 1.08 reward received: -1.60\n",
      "action taken: 1.12 reward received: -1.47\n",
      "action taken: 1.12 reward received: -1.46\n",
      "action taken: 1.10 reward received: -1.58\n",
      "action taken: 1.02 reward received: -1.83\n",
      "action taken: 0.88 reward received: -2.23\n",
      "action taken: 0.74 reward received: -2.81\n",
      "action taken: 0.55 reward received: -3.62\n",
      "action taken: 0.40 reward received: -4.70\n",
      "action taken: 0.25 reward received: -6.07\n",
      "action taken: 0.13 reward received: -7.72\n",
      "action taken: 0.04 reward received: -9.62\n",
      "action taken: 0.06 reward received: -11.68\n",
      "action taken: 0.08 reward received: -13.38\n",
      "action taken: 0.03 reward received: -11.55\n",
      "action taken: -0.06 reward received: -9.71\n",
      "action taken: -0.18 reward received: -7.96\n",
      "action taken: -0.31 reward received: -6.36\n",
      "action taken: -0.45 reward received: -5.00\n",
      "action taken: -0.59 reward received: -3.89\n",
      "action taken: -0.72 reward received: -3.02\n",
      "action taken: -0.84 reward received: -2.38\n",
      "action taken: -0.95 reward received: -1.93\n",
      "action taken: -1.04 reward received: -1.64\n",
      "action taken: -1.07 reward received: -1.50\n",
      "action taken: -1.04 reward received: -1.49\n",
      "action taken: -0.99 reward received: -1.60\n",
      "action taken: -0.89 reward received: -1.85\n",
      "action taken: -0.76 reward received: -2.26\n",
      "action taken: -0.66 reward received: -2.86\n",
      "action taken: -0.56 reward received: -3.70\n",
      "action taken: -0.44 reward received: -4.79\n",
      "action taken: -0.37 reward received: -6.17\n",
      "action taken: -0.28 reward received: -7.82\n",
      "action taken: -0.14 reward received: -9.69\n",
      "action taken: -0.09 reward received: -11.71\n",
      "action taken: -0.04 reward received: -13.24\n",
      "action taken: 0.05 reward received: -11.43\n",
      "action taken: 0.15 reward received: -9.62\n",
      "action taken: 0.27 reward received: -7.89\n",
      "action taken: 0.39 reward received: -6.32\n",
      "action taken: 0.52 reward received: -4.98\n",
      "action taken: 0.64 reward received: -3.88\n",
      "action taken: 0.76 reward received: -3.02\n",
      "action taken: 0.87 reward received: -2.38\n",
      "action taken: 0.97 reward received: -1.93\n",
      "action taken: 1.07 reward received: -1.65\n",
      "action taken: 1.11 reward received: -1.51\n",
      "action taken: 1.11 reward received: -1.49\n",
      "action taken: 1.10 reward received: -1.59\n",
      "action taken: 1.02 reward received: -1.83\n",
      "action taken: 0.88 reward received: -2.22\n",
      "action taken: 0.75 reward received: -2.80\n",
      "action taken: 0.56 reward received: -3.60\n",
      "action taken: 0.41 reward received: -4.66\n",
      "action taken: 0.27 reward received: -6.01\n",
      "action taken: 0.14 reward received: -7.65\n",
      "action taken: 0.04 reward received: -9.53\n",
      "action taken: 0.06 reward received: -11.57\n",
      "action taken: 0.07 reward received: -13.42\n",
      "action taken: 0.01 reward received: -11.60\n",
      "action taken: -0.07 reward received: -9.77\n",
      "action taken: -0.19 reward received: -8.02\n",
      "action taken: -0.32 reward received: -6.43\n",
      "action taken: -0.46 reward received: -5.06\n",
      "action taken: -0.59 reward received: -3.94\n",
      "action taken: -0.72 reward received: -3.06\n",
      "action taken: -0.84 reward received: -2.41\n",
      "action taken: -0.95 reward received: -1.96\n",
      "action taken: -1.04 reward received: -1.67\n",
      "action taken: -1.07 reward received: -1.53\n",
      "action taken: -1.04 reward received: -1.51\n",
      "action taken: -0.99 reward received: -1.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action taken: -0.88 reward received: -1.87\n",
      "action taken: -0.76 reward received: -2.28\n",
      "action taken: -0.65 reward received: -2.89\n",
      "action taken: -0.55 reward received: -3.73\n",
      "action taken: -0.43 reward received: -4.84\n",
      "action taken: -0.37 reward received: -6.22\n",
      "action taken: -0.27 reward received: -7.87\n",
      "action taken: -0.14 reward received: -9.74\n",
      "action taken: -0.09 reward received: -11.75\n",
      "action taken: -0.03 reward received: -13.16\n",
      "action taken: 0.05 reward received: -11.36\n",
      "action taken: 0.16 reward received: -9.55\n",
      "action taken: 0.28 reward received: -7.83\n",
      "action taken: 0.40 reward received: -6.28\n",
      "action taken: 0.53 reward received: -4.94\n",
      "action taken: 0.65 reward received: -3.85\n",
      "action taken: 0.76 reward received: -3.00\n",
      "action taken: 0.87 reward received: -2.37\n",
      "action taken: 0.98 reward received: -1.93\n",
      "action taken: 1.07 reward received: -1.66\n",
      "action taken: 1.11 reward received: -1.52\n",
      "action taken: 1.11 reward received: -1.51\n",
      "action taken: 1.10 reward received: -1.62\n",
      "action taken: 1.01 reward received: -1.87\n",
      "action taken: 0.88 reward received: -2.27\n",
      "action taken: 0.74 reward received: -2.86\n",
      "action taken: 0.54 reward received: -3.68\n",
      "action taken: 0.39 reward received: -4.76\n",
      "action taken: 0.24 reward received: -6.14\n",
      "action taken: 0.11 reward received: -7.79\n",
      "action taken: 0.03 reward received: -9.69\n",
      "action taken: 0.05 reward received: -11.74\n",
      "action taken: 0.07 reward received: -13.26\n",
      "action taken: 0.02 reward received: -11.44\n",
      "action taken: -0.07 reward received: -9.62\n",
      "action taken: -0.19 reward received: -7.87\n",
      "action taken: -0.33 reward received: -6.30\n",
      "action taken: -0.47 reward received: -4.95\n",
      "action taken: -0.60 reward received: -3.85\n",
      "action taken: -0.73 reward received: -3.00\n",
      "action taken: -0.85 reward received: -2.37\n",
      "action taken: -0.96 reward received: -1.94\n",
      "action taken: -1.05 reward received: -1.66\n",
      "action taken: -1.08 reward received: -1.53\n",
      "action taken: -1.05 reward received: -1.53\n",
      "action taken: -1.00 reward received: -1.65\n",
      "action taken: -0.89 reward received: -1.92\n",
      "action taken: -0.77 reward received: -2.35\n",
      "action taken: -0.66 reward received: -2.98\n",
      "action taken: -0.56 reward received: -3.84\n",
      "action taken: -0.44 reward received: -4.97\n",
      "action taken: -0.37 reward received: -6.38\n",
      "action taken: -0.27 reward received: -8.05\n",
      "action taken: -0.14 reward received: -9.93\n",
      "action taken: -0.08 reward received: -11.94\n",
      "action taken: -0.03 reward received: -12.96\n",
      "action taken: 0.06 reward received: -11.16\n",
      "action taken: 0.17 reward received: -9.36\n",
      "action taken: 0.29 reward received: -7.66\n",
      "action taken: 0.42 reward received: -6.14\n",
      "action taken: 0.54 reward received: -4.83\n",
      "action taken: 0.66 reward received: -3.77\n",
      "action taken: 0.78 reward received: -2.94\n",
      "action taken: 0.89 reward received: -2.34\n",
      "action taken: 0.99 reward received: -1.92\n",
      "action taken: 1.08 reward received: -1.66\n",
      "action taken: 1.12 reward received: -1.53\n",
      "action taken: 1.12 reward received: -1.54\n",
      "action taken: 1.11 reward received: -1.67\n",
      "action taken: 1.02 reward received: -1.94\n",
      "action taken: 0.89 reward received: -2.37\n",
      "action taken: 0.75 reward received: -2.99\n",
      "action taken: 0.55 reward received: -3.84\n",
      "action taken: 0.39 reward received: -4.95\n",
      "action taken: 0.24 reward received: -6.36\n",
      "action taken: 0.11 reward received: -8.04\n",
      "action taken: 0.02 reward received: -9.95\n",
      "action taken: 0.04 reward received: -11.99\n",
      "action taken: 0.05 reward received: -12.97\n",
      "action taken: 0.00 reward received: -11.16\n"
     ]
    }
   ],
   "source": [
    "ENV_NAME = \"Pendulum-v0\"\n",
    "TIMESTEPS = 13 # T\n",
    "N_SAMPLES = 100  # K\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "ACTION_LOW = env.action_space.low[0]\n",
    "ACTION_HIGH = env.action_space.high[0]\n",
    "\n",
    "noise_mu = 0\n",
    "noise_sigma = 0.3\n",
    "lambda_ = 1\n",
    "\n",
    "Z = 16\n",
    "\n",
    "U = np.random.uniform(low=ACTION_LOW, high=ACTION_HIGH, size=TIMESTEPS)\n",
    "\n",
    "s = env.reset()\n",
    "\n",
    "polo = POLO(K=N_SAMPLES, T=TIMESTEPS, U=U, lambda_=lambda_, noise_mu=noise_mu, \n",
    "            noise_sigma=noise_sigma, u_init=0, memory_size=512, \n",
    "            observation_space=env.observation_space.shape[0], action_space=env.action_space.shape[0], \n",
    "            state_space=len(env.env.state),\n",
    "            net_hidden_layers=16, num_nets=6, gamma=0.99, state_samples=8, gradient_steps=16, noise_gaussian=True)\n",
    "\n",
    "\n",
    "env.render()\n",
    "polo.store_state(s, env.env.state)\n",
    "\n",
    "for t in range(10000):\n",
    "    a = polo.choose_action(env)\n",
    "    s, r, _, _ = env.step([a])\n",
    "    print(\"action taken: {:.2f} reward received: {:.2f}\".format(a, r))\n",
    "    env.render()\n",
    "    polo.store_state(s, env.env.state)\n",
    "    \n",
    "    if t != 0 and t % Z == 0:\n",
    "        polo.learn(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:polo] *",
   "language": "python",
   "name": "conda-env-polo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
